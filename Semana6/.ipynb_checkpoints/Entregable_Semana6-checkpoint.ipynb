{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Semana 6: Implementar un proceso ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo a Desarrollar\n",
    "\n",
    "Para esta entrega se utilizara el modelo proporcionado por el grupo de profesores y tutores:\n",
    "\n",
    "![Modelos](./Modelo_aeropuertos_definitivo.png)\n",
    "\n",
    "Para saber mas informacion sobre el contenido de cada dimension, atributo y medida, puede consultar el diccionario de datos Actualizado [AQUI](./Diccionario%20IV.xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño del ETL:\n",
    "\n",
    "Antes de empezar la implementaciond debemos trabajar en el diseño del proceso de ETL, este diseño se puede observar en la siguiente imagen:\n",
    "\n",
    "![Diseno ETL](./EntregaGrupalS6_Diseno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #1: Setup\n",
    "\n",
    "En esta seccion se hara el setup de la tarea, incluyendo librerias y estableciendo todo los prerequisitos para la correcta ejecucion de lo esperado en la actividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estudiante\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\estudiante\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.types import FloatType, StringType, IntegerType, DateType\n",
    "from pyspark.sql.functions import udf, col, length, isnan, when, count, regexp_replace, abs, percent_rank, row_number,concat,date_format,to_date, upper\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql.window import Window\n",
    "from pandas_profiling import ProfileReport\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import max as spark_max\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import array, struct, explode, floor, col, lit\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as f\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Configuración servidor base de datos transaccional\n",
    "db_shiomar = 'Estudiante_103_202413'\n",
    "pass_shiomar = 'MISO_aabb1122'\n",
    "source_db_connection_string = 'jdbc:mysql://157.253.236.116:8080/ProyectoTransaccional'\n",
    "dest_db_connection_string = 'jdbc:mysql://157.253.236.116:8080/Proyecto_G5_202413'\n",
    "\n",
    "path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'\n",
    "\n",
    "conf=SparkConf() \\\n",
    "    .set('spark.driver.extraClassPath', path_jar_driver) \\\n",
    "    .set(\"spark.network.timeout\", \"600s\") \\\n",
    "    .set(\"spark.executor.heartbeatInterval\", \"100s\") \\\n",
    "    .set(\"spark.rpc.askTimeout\", \"600s\") \\\n",
    "    .set(\"spark.rpc.lookupTimeout\", \"600s\")\n",
    "\n",
    "spark_context = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession\n",
    "\n",
    "def obtener_dataframe_de_bd(db_connection_string, sql, db_user, db_psswd):\n",
    "    df_bd = spark.read.format('jdbc')\\\n",
    "        .option('url', db_connection_string) \\\n",
    "        .option('dbtable', sql) \\\n",
    "        .option('user', db_user) \\\n",
    "        .option('password', db_psswd) \\\n",
    "        .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "        .load()\n",
    "    return df_bd\n",
    "\n",
    "def guardar_db(db_connection_string, df, tabla, db_user, db_psswd):\n",
    "    df.select('*').write.format('jdbc') \\\n",
    "      .mode('append') \\\n",
    "      .option('url', db_connection_string) \\\n",
    "      .option('dbtable', tabla) \\\n",
    "      .option('user', db_user) \\\n",
    "      .option('password', db_psswd) \\\n",
    "      .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #2: Dimensión Aeropuerto\n",
    "\n",
    "En este paso aplicaremos ETL a la Dimension **Aeropuerto**, su fuente de datos viene de la tabla `aeropuertos` de la base de datos de ProyectoTransaccional.\n",
    "\n",
    "Al final del proceso de ETL se espera obtener una nueva tabla llamada `G5_Aeropuerto` en la base de datos de Proyecto_G5_202413 conteniendo las siguiente columnas:\n",
    "* idAeropuerto_DWH\n",
    "* Sigla\n",
    "* IATA\n",
    "* Nombre\n",
    "* Elevacion\n",
    "* NombreMunicipio\n",
    "* NombreDepartamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraccion\n",
    "\n",
    "En esta seccion obtendremos los datos de las fuentes identificadas en nuestro diseño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de Registros de la tabla Aeropuertos obtenidos fueron: 598\n",
      "La tabla extraida queda de la siguiente forma:\n",
      "+-----+----+--------------------+---------+--------------------+------------------+\n",
      "|Sigla|IATA|              Nombre|Elevacion|     NombreMunicipio|NombreDepartamento|\n",
      "+-----+----+--------------------+---------+--------------------+------------------+\n",
      "|  7FO|    |             la isla|      538|       Puerto Gaitán|              meta|\n",
      "|  7FU|    |        la escondida|      564|       Puerto Gaitán|              meta|\n",
      "|  7FW|    |           morichito|      720|        Hato Corozal|          casanare|\n",
      "|  7FX|    |carolina del prin...|     6004|            Carolina|         antioquia|\n",
      "|  7FY|    |               dubai|       82|              Ayapel|           cordoba|\n",
      "|  7FZ|    |          el triunfo|      475|              Orocué|          casanare|\n",
      "|  7GA|    |  baru - hidropuerto|        0| Cartagena de Indias|           bolivar|\n",
      "|  7GB|    |         la carolina|      690|             El Paso|             cesar|\n",
      "|  7GC|    |san felipe del pauto|     3125|            Trinidad|          casanare|\n",
      "|  7GD|    |           velasquez|      617|       Puerto Boyacá|            boyaca|\n",
      "|  7GE|    |           lucitania|      443|              Orocué|          casanare|\n",
      "|  7GF|    |            la union|      335|      Paz de Ariporo|          casanare|\n",
      "|  7GG|    |          la ilusion|      574|                Maní|          casanare|\n",
      "|  7GH|    |        la venturosa|      246|      Puerto Carreño|           vichada|\n",
      "|  7GI|    |  guayabal del cravo|      442|              Orocué|          casanare|\n",
      "|  7GK|    |    las violetas- ca|      609|   Castilla la Nueva|              meta|\n",
      "|  7GL|    |            la jagua|      787| La Jagua de Ibirico|             cesar|\n",
      "|  7GN|    |          los mangos|       90|              Ayapel|           cordoba|\n",
      "|  7GO|    |           matabrava|      524|San Luis de Palenque|          casanare|\n",
      "|  7GP|    |    el porvenir - ca|      176|   Pijiño del Carmen|         magdalena|\n",
      "+-----+----+--------------------+---------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_aeropuerto = '''(SELECT DISTINCT sigla AS Sigla, iata AS IATA, nombre AS Nombre, elevacion AS Elevacion, municipio AS NombreMunicipio, departamento AS NombreDepartamento FROM ProyectoTransaccional.aeropuertos) AS Temp_aeropuerto'''\n",
    "aeropuerto_df = obtener_dataframe_de_bd(source_db_connection_string, sql_aeropuerto, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de Registros de la tabla Aeropuertos obtenidos fueron: ' + str(aeropuerto_df.count()))\n",
    "print('La tabla extraida queda de la siguiente forma:')\n",
    "aeropuerto_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T1. Eliminar duplicados totales de la tabla:\n",
    "\n",
    "Esta transformacion fue aplicada en la sentencia SQL de la etapa de Extraccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de duplicados totales es de 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = aeropuerto_df.count() - aeropuerto_df.distinct().count()\n",
    "print('La cantidad de duplicados totales es de ' + str(duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T2. Adecuación del Formato de la Tabla según la Expectativa de Salida:\n",
    "\n",
    "Esta transformacion fue aplicada en la sentencia SQL de la etapa de Extraccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla actual tiene el siguiente formato: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Sigla,StringType,true),StructField(IATA,StringType,true),StructField(Nombre,StringType,true),StructField(Elevacion,IntegerType,true),StructField(NombreMunicipio,StringType,true),StructField(NombreDepartamento,StringType,true)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('La tabla actual tiene el siguiente formato: ')\n",
    "aeropuerto_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3. Creación de la columna idAeropuero_DWH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla Transformada queda de la siguiente forma:\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "|idAeropuerto_DWH|Sigla|IATA|              Nombre|Elevacion|     NombreMunicipio|NombreDepartamento|\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "|               1|  7FO|    |             la isla|      538|       Puerto Gaitán|              meta|\n",
      "|               2|  7FU|    |        la escondida|      564|       Puerto Gaitán|              meta|\n",
      "|               3|  7FW|    |           morichito|      720|        Hato Corozal|          casanare|\n",
      "|               4|  7FX|    |carolina del prin...|     6004|            Carolina|         antioquia|\n",
      "|               5|  7FY|    |               dubai|       82|              Ayapel|           cordoba|\n",
      "|               6|  7FZ|    |          el triunfo|      475|              Orocué|          casanare|\n",
      "|               7|  7GA|    |  baru - hidropuerto|        0| Cartagena de Indias|           bolivar|\n",
      "|               8|  7GB|    |         la carolina|      690|             El Paso|             cesar|\n",
      "|               9|  7GC|    |san felipe del pauto|     3125|            Trinidad|          casanare|\n",
      "|              10|  7GD|    |           velasquez|      617|       Puerto Boyacá|            boyaca|\n",
      "|              11|  7GE|    |           lucitania|      443|              Orocué|          casanare|\n",
      "|              12|  7GF|    |            la union|      335|      Paz de Ariporo|          casanare|\n",
      "|              13|  7GG|    |          la ilusion|      574|                Maní|          casanare|\n",
      "|              14|  7GH|    |        la venturosa|      246|      Puerto Carreño|           vichada|\n",
      "|              15|  7GI|    |  guayabal del cravo|      442|              Orocué|          casanare|\n",
      "|              16|  7GK|    |    las violetas- ca|      609|   Castilla la Nueva|              meta|\n",
      "|              17|  7GL|    |            la jagua|      787| La Jagua de Ibirico|             cesar|\n",
      "|              18|  7GN|    |          los mangos|       90|              Ayapel|           cordoba|\n",
      "|              19|  7GO|    |           matabrava|      524|San Luis de Palenque|          casanare|\n",
      "|              20|  7GP|    |    el porvenir - ca|      176|   Pijiño del Carmen|         magdalena|\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuerto_df = aeropuerto_df.coalesce(1).withColumn('idAeropuerto_DWH', f.monotonically_increasing_id() + 1)\n",
    "aeropuerto_df = aeropuerto_df.select('idAeropuerto_DWH','Sigla', 'IATA', 'Nombre', 'Elevacion', 'NombreMunicipio', 'NombreDepartamento' )\n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "aeropuerto_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T4. Rellenar valores vacíos de la columna IATA con valores por defecto.\n",
    "\n",
    "Para esta transformacion se utilizara el IATA de `ZZZ` ya que este no existe en el listado de IATAs asignados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla Transformada queda de la siguiente forma:\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "|idAeropuerto_DWH|Sigla|IATA|              Nombre|Elevacion|     NombreMunicipio|NombreDepartamento|\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "|               1|  7FO| ZZZ|             la isla|      538|       Puerto Gaitán|              meta|\n",
      "|               2|  7FU| ZZZ|        la escondida|      564|       Puerto Gaitán|              meta|\n",
      "|               3|  7FW| ZZZ|           morichito|      720|        Hato Corozal|          casanare|\n",
      "|               4|  7FX| ZZZ|carolina del prin...|     6004|            Carolina|         antioquia|\n",
      "|               5|  7FY| ZZZ|               dubai|       82|              Ayapel|           cordoba|\n",
      "|               6|  7FZ| ZZZ|          el triunfo|      475|              Orocué|          casanare|\n",
      "|               7|  7GA| ZZZ|  baru - hidropuerto|        0| Cartagena de Indias|           bolivar|\n",
      "|               8|  7GB| ZZZ|         la carolina|      690|             El Paso|             cesar|\n",
      "|               9|  7GC| ZZZ|san felipe del pauto|     3125|            Trinidad|          casanare|\n",
      "|              10|  7GD| ZZZ|           velasquez|      617|       Puerto Boyacá|            boyaca|\n",
      "|              11|  7GE| ZZZ|           lucitania|      443|              Orocué|          casanare|\n",
      "|              12|  7GF| ZZZ|            la union|      335|      Paz de Ariporo|          casanare|\n",
      "|              13|  7GG| ZZZ|          la ilusion|      574|                Maní|          casanare|\n",
      "|              14|  7GH| ZZZ|        la venturosa|      246|      Puerto Carreño|           vichada|\n",
      "|              15|  7GI| ZZZ|  guayabal del cravo|      442|              Orocué|          casanare|\n",
      "|              16|  7GK| ZZZ|    las violetas- ca|      609|   Castilla la Nueva|              meta|\n",
      "|              17|  7GL| ZZZ|            la jagua|      787| La Jagua de Ibirico|             cesar|\n",
      "|              18|  7GN| ZZZ|          los mangos|       90|              Ayapel|           cordoba|\n",
      "|              19|  7GO| ZZZ|           matabrava|      524|San Luis de Palenque|          casanare|\n",
      "|              20|  7GP| ZZZ|    el porvenir - ca|      176|   Pijiño del Carmen|         magdalena|\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuerto_df = aeropuerto_df.withColumn(\"IATA\", when(col(\"IATA\") == \"\", \"ZZZ\").otherwise(col('IATA')))\n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "aeropuerto_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificamos los valores de IATA de la tabla resultante:\n",
      "+----+-----+\n",
      "|IATA|count|\n",
      "+----+-----+\n",
      "| ZZZ|  494|\n",
      "| ECO|    1|\n",
      "| ACD|    1|\n",
      "| ACL|    1|\n",
      "| ACR|    1|\n",
      "| ADZ|    1|\n",
      "| AFI|    1|\n",
      "| APO|    1|\n",
      "| ARO|    1|\n",
      "| ARQ|    1|\n",
      "| AUC|    1|\n",
      "| BAQ|    1|\n",
      "| BOG|    1|\n",
      "| BUN|    1|\n",
      "| CIM|    1|\n",
      "| CLO|    1|\n",
      "| COG|    1|\n",
      "| CPL|    1|\n",
      "| CTG|    1|\n",
      "| CUC|    1|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Verificamos los valores de IATA de la tabla resultante:\")\n",
    "aeropuerto_df.groupBy(\"IATA\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5. Creación del Aeropuerto con idAeropuerto_DWH cero, para ser usado con Aeropuertos Internacionales sin datos.\n",
    "\n",
    "Esta transformacion tiene la intencio de crear un campo para los posibles valores en done la tabla de `HechosVuelos` no tenga valores  y evitar a toda costa que tenga campos vacios, null o NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla Transformada queda de la siguiente forma:\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "|idAeropuerto_DWH|Sigla|IATA|              Nombre|Elevacion|     NombreMunicipio|NombreDepartamento|\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "|               0|  INT| ZZZ|             Missing|        0|       Internacional|     Internacional|\n",
      "|               1|  7FO| ZZZ|             la isla|      538|       Puerto Gaitán|              meta|\n",
      "|               2|  7FU| ZZZ|        la escondida|      564|       Puerto Gaitán|              meta|\n",
      "|               3|  7FW| ZZZ|           morichito|      720|        Hato Corozal|          casanare|\n",
      "|               4|  7FX| ZZZ|carolina del prin...|     6004|            Carolina|         antioquia|\n",
      "|               5|  7FY| ZZZ|               dubai|       82|              Ayapel|           cordoba|\n",
      "|               6|  7FZ| ZZZ|          el triunfo|      475|              Orocué|          casanare|\n",
      "|               7|  7GA| ZZZ|  baru - hidropuerto|        0| Cartagena de Indias|           bolivar|\n",
      "|               8|  7GB| ZZZ|         la carolina|      690|             El Paso|             cesar|\n",
      "|               9|  7GC| ZZZ|san felipe del pauto|     3125|            Trinidad|          casanare|\n",
      "|              10|  7GD| ZZZ|           velasquez|      617|       Puerto Boyacá|            boyaca|\n",
      "|              11|  7GE| ZZZ|           lucitania|      443|              Orocué|          casanare|\n",
      "|              12|  7GF| ZZZ|            la union|      335|      Paz de Ariporo|          casanare|\n",
      "|              13|  7GG| ZZZ|          la ilusion|      574|                Maní|          casanare|\n",
      "|              14|  7GH| ZZZ|        la venturosa|      246|      Puerto Carreño|           vichada|\n",
      "|              15|  7GI| ZZZ|  guayabal del cravo|      442|              Orocué|          casanare|\n",
      "|              16|  7GK| ZZZ|    las violetas- ca|      609|   Castilla la Nueva|              meta|\n",
      "|              17|  7GL| ZZZ|            la jagua|      787| La Jagua de Ibirico|             cesar|\n",
      "|              18|  7GN| ZZZ|          los mangos|       90|              Ayapel|           cordoba|\n",
      "|              19|  7GO| ZZZ|           matabrava|      524|San Luis de Palenque|          casanare|\n",
      "+----------------+-----+----+--------------------+---------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aero_0 = [('0','INT','ZZZ','Missing','0','Internacional','Internacional')]\n",
    "columns = ['idAeropuerto_DWH','Sigla', 'IATA', 'Nombre', 'Elevacion', 'NombreMunicipio', 'NombreDepartamento']\n",
    "aero_0 = spark.createDataFrame(data=aero_0,schema=columns)\n",
    "aeropuerto_df = aeropuerto_df.union(aero_0)\n",
    "aeropuerto_df = aeropuerto_df.withColumn('idAeropuerto_DWH',col('idAeropuerto_DWH').cast('int')).orderBy(col('idAeropuerto_DWH'))\n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "aeropuerto_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga\n",
    "Se carga el dataframe procesado en una nueva tabla segun el diseño de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, aeropuerto_df,'Proyecto_G5_202413.G5_Aeropuerto', db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #3: Dimensión Tipo Vuelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso aplicaremos ETL a la Dimension **TipoVuelo**, su fuente de datos viene de la tabla `Vuelos` de la base de datos de ProyectoTransaccional.\n",
    "\n",
    "Al final del proceso de ETL se espera obtener una nueva tabla llamada `G5_TipoVuelo` en la base de datos de Proyecto_G5_202413 conteniendo las siguiente columnas:\n",
    "* idTipoVuelo_DWH\n",
    "* idTipovuelo_T\n",
    "* nombreTipo\n",
    "* tipoEquipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraccion\n",
    "\n",
    "En esta seccion obtendremos los datos de las fuentes identificadas en nuestro diseño.\n",
    "\n",
    "T1. Se crea un dataframe que contiene unicamente las columnas requeridas tipo_vuelo, tipo_equipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de Registros de la tabla Vuelos obtenidos fueron: 563265\n",
      "El dataFrame extraido queda de la siguiente forma:\n",
      "+----------+-----------+\n",
      "|tipo_vuelo|tipo_equipo|\n",
      "+----------+-----------+\n",
      "|         R|       JS32|\n",
      "|         R|       JS32|\n",
      "|         R|       JS32|\n",
      "|         R|       JS32|\n",
      "|         R|       DHC6|\n",
      "|         R|       DHC6|\n",
      "|         R|       A306|\n",
      "|         R|       DHC6|\n",
      "|         R|       A306|\n",
      "|         R|       DHC6|\n",
      "|         R|       A306|\n",
      "|         R|       DHC6|\n",
      "|         R|       A306|\n",
      "|         R|       DHC6|\n",
      "|         R|       A306|\n",
      "|         R|       DHC6|\n",
      "|         R|       A306|\n",
      "|         R|       DHC6|\n",
      "|         R|       A306|\n",
      "|         R|       DHC6|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_vuelos = '''(SELECT  tipo_vuelo, tipo_equipo FROM ProyectoTransaccional.vuelos) AS Temp_vuelos'''\n",
    "vuelos_df = obtener_dataframe_de_bd(source_db_connection_string, sql_vuelos, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de Registros de la tabla Vuelos obtenidos fueron: ' + str(vuelos_df.count()))\n",
    "print('El dataFrame extraido queda de la siguiente forma:')\n",
    "vuelos_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T2. Eliminar duplicados totales de la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de duplicados totales es de 562893\n",
      "Dataframe sin duplicados\n",
      "+----------+-----------+\n",
      "|tipo_vuelo|tipo_equipo|\n",
      "+----------+-----------+\n",
      "|         T|       D28T|\n",
      "|         C|       A320|\n",
      "|         C|       A343|\n",
      "|         T|       GLF2|\n",
      "|         R|       DC95|\n",
      "|         R|       B733|\n",
      "|         T|       AC90|\n",
      "|         A|       DH8D|\n",
      "|         A|       E170|\n",
      "|         T|       AN26|\n",
      "|         A|        A30|\n",
      "|         R|        747|\n",
      "|         A|       B734|\n",
      "|         R|       C295|\n",
      "|         T|       C170|\n",
      "|         R|       B731|\n",
      "|         T|       C25C|\n",
      "|         A|        AT4|\n",
      "|         R|       A318|\n",
      "|         R|       DC10|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Cantidad Final: 372\n"
     ]
    }
   ],
   "source": [
    "duplicates = vuelos_df.count() - vuelos_df.distinct().count()\n",
    "vuelos_df_whitout_duplicates = vuelos_df.distinct()\n",
    "print('La cantidad de duplicados totales es de ' + str(duplicates))\n",
    "print('Dataframe sin duplicados')\n",
    "vuelos_df_whitout_duplicates.show()\n",
    "print('Cantidad Final: '+str(vuelos_df_whitout_duplicates.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3. Se crea columna nombretipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|tipo_vuelo| nombreTipo|\n",
      "+----------+-----------+\n",
      "|         R|    regular|\n",
      "|         T|       taxi|\n",
      "|         C|    chárter|\n",
      "|         A|adicionales|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creamos DF con el diccionario dado por el negocio\n",
    "df = pd.DataFrame({'tipo_vuelo': ['R','T','C','A'], 'nombreTipo': ['regular', 'taxi', 'chárter', 'adicionales']})\n",
    "\n",
    "#mostrar DatraFrame\n",
    "diccionarioTipoVuelo=spark.createDataFrame(df)\n",
    "diccionarioTipoVuelo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+\n",
      "|tipo_vuelo|tipo_equipo|nombreTipo|\n",
      "+----------+-----------+----------+\n",
      "|         R|       A320|   regular|\n",
      "|         R|       B720|   regular|\n",
      "|         R|       B753|   regular|\n",
      "|         R|       DH8D|   regular|\n",
      "|         R|       DH8A|   regular|\n",
      "|         R|        Y12|   regular|\n",
      "|         R|       AT75|   regular|\n",
      "|         R|        F50|   regular|\n",
      "|         R|        DC3|   regular|\n",
      "|         R|        DC8|   regular|\n",
      "|         R|       MD83|   regular|\n",
      "|         R|       DHC3|   regular|\n",
      "|         R|       DC93|   regular|\n",
      "|         R|       B463|   regular|\n",
      "|         R|        F10|   regular|\n",
      "|         R|       B773|   regular|\n",
      "|         R|       CDC6|   regular|\n",
      "|         R|        767|   regular|\n",
      "|         R|       DHC2|   regular|\n",
      "|         R|       B788|   regular|\n",
      "+----------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creamos un join con el diccionario tipovuelos\n",
    "vuelos_df_whitout_duplicates = vuelos_df_whitout_duplicates.join(diccionarioTipoVuelo,how = 'inner',  on='tipo_vuelo')\n",
    "# mostramos el DF final\n",
    "print(vuelos_df_whitout_duplicates.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T4. Adecuación del Formato de la Tabla según la Expectativa de Salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+---------------+-------------+\n",
      "|tipo_vuelo|tipo_equipo|nombreTipo|idTipoVuelo_DWH|idTipovuelo_T|\n",
      "+----------+-----------+----------+---------------+-------------+\n",
      "|         R|       A320|   regular|              1|        RA320|\n",
      "|         R|       B720|   regular|              2|        RB720|\n",
      "|         R|       B753|   regular|              3|        RB753|\n",
      "|         R|       DH8D|   regular|              4|        RDH8D|\n",
      "|         R|       DH8A|   regular|              5|        RDH8A|\n",
      "|         R|        Y12|   regular|              6|         RY12|\n",
      "|         R|       AT75|   regular|              7|        RAT75|\n",
      "|         R|        F50|   regular|              8|         RF50|\n",
      "|         R|        DC3|   regular|              9|         RDC3|\n",
      "|         R|        DC8|   regular|             10|         RDC8|\n",
      "|         R|       MD83|   regular|             11|        RMD83|\n",
      "|         R|       DHC3|   regular|             12|        RDHC3|\n",
      "|         R|       DC93|   regular|             13|        RDC93|\n",
      "|         R|       B463|   regular|             14|        RB463|\n",
      "|         R|        F10|   regular|             15|         RF10|\n",
      "|         R|       B773|   regular|             16|        RB773|\n",
      "|         R|       CDC6|   regular|             17|        RCDC6|\n",
      "|         R|        767|   regular|             18|         R767|\n",
      "|         R|       DHC2|   regular|             19|        RDHC2|\n",
      "|         R|       B788|   regular|             20|        RB788|\n",
      "+----------+-----------+----------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Agregar columna idTipoVuelo_DWH\n",
    "vuelos_df_whitout_duplicates = vuelos_df_whitout_duplicates.coalesce(1).withColumn('idTipoVuelo_DWH', f.monotonically_increasing_id() + 1)\n",
    "#Agregar columna idTipovuelo_T\n",
    "vuelos_df_whitout_duplicates = vuelos_df_whitout_duplicates.coalesce(1).withColumn('idTipovuelo_T', concat(vuelos_df_whitout_duplicates.tipo_vuelo,vuelos_df_whitout_duplicates.tipo_equipo))\n",
    "# mostramos el DF final\n",
    "print(vuelos_df_whitout_duplicates.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla actual tiene el siguiente formato: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(tipo_vuelo,StringType,true),StructField(tipo_equipo,StringType,true),StructField(nombreTipo,StringType,true),StructField(idTipoVuelo_DWH,LongType,false),StructField(idTipovuelo_T,StringType,true)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('La tabla actual tiene el siguiente formato: ')\n",
    "vuelos_df_whitout_duplicates.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5. Se seleccionan columnas de salida de la transformacion con los nombres finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla final: \n",
      "+---------------+-------------+----------+----------+\n",
      "|idTipoVuelo_DWH|idTipovuelo_T|nombreTipo|tipoEquipo|\n",
      "+---------------+-------------+----------+----------+\n",
      "|              1|        RA320|   regular|      A320|\n",
      "|              2|        RB720|   regular|      B720|\n",
      "|              3|        RB753|   regular|      B753|\n",
      "|              4|        RDH8D|   regular|      DH8D|\n",
      "|              5|        RDH8A|   regular|      DH8A|\n",
      "|              6|         RY12|   regular|       Y12|\n",
      "|              7|        RAT75|   regular|      AT75|\n",
      "|              8|         RF50|   regular|       F50|\n",
      "|              9|         RDC3|   regular|       DC3|\n",
      "|             10|         RDC8|   regular|       DC8|\n",
      "|             11|        RMD83|   regular|      MD83|\n",
      "|             12|        RDHC3|   regular|      DHC3|\n",
      "|             13|        RDC93|   regular|      DC93|\n",
      "|             14|        RB463|   regular|      B463|\n",
      "|             15|         RF10|   regular|       F10|\n",
      "|             16|        RB773|   regular|      B773|\n",
      "|             17|        RCDC6|   regular|      CDC6|\n",
      "|             18|         R767|   regular|       767|\n",
      "|             19|        RDHC2|   regular|      DHC2|\n",
      "|             20|        RB788|   regular|      B788|\n",
      "+---------------+-------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataframe final\n",
    "df_tipo_vuelos = vuelos_df_whitout_duplicates.selectExpr('idTipoVuelo_DWH AS idTipoVuelo_DWH', 'idTipovuelo_T AS idTipovuelo_T', 'nombreTipo AS nombreTipo', 'tipo_equipo AS tipoEquipo')\n",
    "print('La tabla final: ')\n",
    "df_tipo_vuelos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga\n",
    "Se carga el dataframe procesado en una nueva tabla segun el diseño de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, df_tipo_vuelos,'Proyecto_G5_202413.G5_TipoVuelo', db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #4: Dimensión Trafico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso aplicaremos ETL a la **Dimension Trafico** ,  su fuente de datos viene de la tabla Vuelos de la base de datos de ProyectoTransaccional.\n",
    "\n",
    "Al final del proceso de ETL se espera obtener una nueva tabla llamada G5_TipoVuelo en la base de datos de Proyecto_G5_202413 conteniendo las siguiente columnas:\n",
    "\n",
    "* IdTrafico_DWH \n",
    "* idTrafico_T\n",
    "* NombreTrafico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraccion\n",
    "\n",
    "En esta seccion obtendremos los datos de las fuentes identificadas en nuestro diseño.\n",
    "\n",
    "T1. Se crea un dataframe que contiene unicamente la columna requerida trafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de Registros de la tabla Vuelos obtenidos fueron: 563265\n",
      "El dataFrame extraido queda de la siguiente forma:\n",
      "+-------+\n",
      "|trafico|\n",
      "+-------+\n",
      "|      N|\n",
      "|      N|\n",
      "|      N|\n",
      "|      N|\n",
      "|      N|\n",
      "|      N|\n",
      "|      I|\n",
      "|      N|\n",
      "|      I|\n",
      "|      N|\n",
      "|      I|\n",
      "|      N|\n",
      "|      I|\n",
      "|      N|\n",
      "|      I|\n",
      "|      N|\n",
      "|      I|\n",
      "|      N|\n",
      "|      I|\n",
      "|      N|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_vuelos_trafico = '''(SELECT  trafico FROM ProyectoTransaccional.vuelos) AS Temp_vuelos_trafico'''\n",
    "vuelos_trafico_df = obtener_dataframe_de_bd(source_db_connection_string, sql_vuelos_trafico, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de Registros de la tabla Vuelos obtenidos fueron: ' + str(vuelos_trafico_df.count()))\n",
    "print('El dataFrame extraido queda de la siguiente forma:')\n",
    "vuelos_trafico_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformacion\n",
    "T2. Eliminar duplicados totales de la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de duplicados totales es de 563262\n",
      "Dataframe sin duplicados\n",
      "+-------+\n",
      "|trafico|\n",
      "+-------+\n",
      "|      E|\n",
      "|      N|\n",
      "|      I|\n",
      "+-------+\n",
      "\n",
      "Cantidad Final: 3\n"
     ]
    }
   ],
   "source": [
    "duplicates_trafico = vuelos_trafico_df.count() - vuelos_trafico_df.distinct().count()\n",
    "vuelos_trafico_df_whitout_duplicates = vuelos_trafico_df.distinct()\n",
    "print('La cantidad de duplicados totales es de ' + str(duplicates_trafico))\n",
    "print('Dataframe sin duplicados')\n",
    "vuelos_trafico_df_whitout_duplicates.show()\n",
    "print('Cantidad Final: '+str(vuelos_trafico_df_whitout_duplicates.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3. Se crea columna nombreTrafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|trafico|    nombreTrafico|\n",
      "+-------+-----------------+\n",
      "|      E|postal o urgentes|\n",
      "|      N|         Nacional|\n",
      "|      I|    Internacional|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creamos DF con el diccionario dado por el negocio\n",
    "df_dic_trafico = pd.DataFrame({'trafico': ['E','N','I'], 'nombreTrafico': ['postal o urgentes', 'Nacional', 'Internacional']})\n",
    "\n",
    "#mostrar DatraFrame\n",
    "diccionarioTrafico=spark.createDataFrame(df_dic_trafico)\n",
    "diccionarioTrafico.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|trafico|    nombreTrafico|\n",
      "+-------+-----------------+\n",
      "|      E|postal o urgentes|\n",
      "|      N|         Nacional|\n",
      "|      I|    Internacional|\n",
      "+-------+-----------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creamos un join con el diccionario tipovuelos\n",
    "vuelos_trafico_df_whitout_duplicates = vuelos_trafico_df_whitout_duplicates.join(diccionarioTrafico,how = 'inner',  on='trafico')\n",
    "# mostramos el DF final\n",
    "print(vuelos_trafico_df_whitout_duplicates.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T4. Adecuación del Formato de la Tabla según la Expectativa de Salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------+\n",
      "|trafico|    nombreTrafico|IdTrafico_DWH|\n",
      "+-------+-----------------+-------------+\n",
      "|      E|postal o urgentes|            1|\n",
      "|      N|         Nacional|            2|\n",
      "|      I|    Internacional|            3|\n",
      "+-------+-----------------+-------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Agregar columna idTipoVuelo_DWH\n",
    "vuelos_trafico_df_whitout_duplicates = vuelos_trafico_df_whitout_duplicates.coalesce(1).withColumn('IdTrafico_DWH', f.monotonically_increasing_id() + 1)\n",
    "# mostramos el DF final\n",
    "print(vuelos_trafico_df_whitout_duplicates.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla actual tiene el siguiente formato: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(trafico,StringType,true),StructField(nombreTrafico,StringType,true),StructField(IdTrafico_DWH,LongType,false)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('La tabla actual tiene el siguiente formato: ')\n",
    "vuelos_trafico_df_whitout_duplicates.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5. Se seleccionan columnas de salida de la transformacion con los nombres finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla final: \n",
      "+-------------+-----------+-----------------+\n",
      "|IdTrafico_DWH|idTrafico_T|    nombreTrafico|\n",
      "+-------------+-----------+-----------------+\n",
      "|            1|          E|postal o urgentes|\n",
      "|            2|          N|         Nacional|\n",
      "|            3|          I|    Internacional|\n",
      "+-------------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataframe final\n",
    "df_trafico = vuelos_trafico_df_whitout_duplicates.selectExpr('IdTrafico_DWH AS IdTrafico_DWH', 'trafico AS idTrafico_T', 'nombreTrafico AS nombreTrafico')\n",
    "print('La tabla final: ')\n",
    "df_trafico.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga\n",
    "Se carga el dataframe procesado en una nueva tabla segun el diseño de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, df_trafico,'Proyecto_G5_202413.G5_Trafico',db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Paso #5: Dimensión Geografía con Demografía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extraccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_proyecciones = '''(SELECT * FROM ProyectoTransaccional.proyecciones) AS Temp_proyecciones'''\n",
    "sql_pib = '''(SELECT * FROM ProyectoTransaccional.pib) AS Temp_pib'''\n",
    "sql_departamentos = '''(SELECT * FROM ProyectoTransaccional.divipola) AS Temp_divipola'''\n",
    "\n",
    "departamentos = obtener_dataframe_de_bd(source_db_connection_string, sql_departamentos, db_shiomar, pass_shiomar)\n",
    "pib = obtener_dataframe_de_bd(source_db_connection_string, sql_pib, db_shiomar, pass_shiomar)\n",
    "proyecciones = obtener_dataframe_de_bd(source_db_connection_string, sql_proyecciones, db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divipola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan duplicados totales de divipola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15758, 7879)\n"
     ]
    }
   ],
   "source": [
    "print((departamentos.count(),departamentos.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "departamentos = departamentos.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7879, 7879)\n"
     ]
    }
   ],
   "source": [
    "print((departamentos.count(),departamentos.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcion nombre departamento bogota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace part of string with another stringc0\n",
    "departamentos = departamentos.withColumn('NombreDepartamento', regexp_replace('NombreDepartamento', 'd0,', 'distrito'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "departamentos = departamentos.withColumn('NombreDepartamento', regexp_replace('NombreDepartamento', 'c0,', 'capital'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correccion nombre municipio bogota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "departamentos = departamentos.withColumn('NombreMunicipio', regexp_replace('NombreMunicipio', 'D0,', 'DISTRITO'))\n",
    "departamentos = departamentos.withColumn('NombreMunicipio', regexp_replace('NombreDepartamento', 'C0,', 'CAPITAL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+-------------------+--------------------+--------------------+-------------------+-----------------+--------------+-------------+--------------------+-------------------------------------+-----------------------+\n",
      "|CodigoDepartamento|CodigoMunicipio|CodigoCentroPoblado|  NombreDepartamento|     NombreMunicipio|NombreCentroPoblado|TipoCentroPoblado|      Longitud|      Latitud|     Nombre Distrito|Municipio/AreasNoMunicipalizadas(ANM)|NombreAreaMetropolitana|\n",
      "+------------------+---------------+-------------------+--------------------+--------------------+-------------------+-----------------+--------------+-------------+--------------------+-------------------------------------+-----------------------+\n",
      "|                11|          11001|           11001010|bogota, distrito ...|bogota, distrito ...|           LA UNIÓN|   CENTRO POBLADO|-74.3635089446|3.98536782367|BOGOTÁ, DISTRITO ...|                            MUNICIPIO|                   null|\n",
      "|                11|          11001|           11001014|bogota, distrito ...|bogota, distrito ...|      NUEVA GRANADA|   CENTRO POBLADO|-74.3593728582| 3.8904373526|BOGOTÁ, DISTRITO ...|                            MUNICIPIO|                   null|\n",
      "|                11|          11001|           11001007|bogota, distrito ...|bogota, distrito ...|          PASQUILLA|   CENTRO POBLADO|-74.1562512884|4.44434811547|BOGOTÁ, DISTRITO ...|                            MUNICIPIO|                   null|\n",
      "|                11|          11001|           11001013|bogota, distrito ...|bogota, distrito ...|         EL DESTINO|   CENTRO POBLADO| -74.138352034|4.40901089154|BOGOTÁ, DISTRITO ...|                            MUNICIPIO|                   null|\n",
      "|                11|          11001|           11001015|bogota, distrito ...|bogota, distrito ...|         QUIBA BAJO|   CENTRO POBLADO| -74.167560318|4.52732041371|BOGOTÁ, DISTRITO ...|                            MUNICIPIO|                   null|\n",
      "+------------------+---------------+-------------------+--------------------+--------------------+-------------------+-----------------+--------------+-------------+--------------------+-------------------------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departamentos.filter(col(\"NombreDepartamento\").contains(\"bogota\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiar NombreDepartamento y NombreMunicipio a mayuscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "departamentos = departamentos.withColumn('NombreDepartamento', upper('NombreDepartamento'))\n",
    "departamentos = departamentos.withColumn('NombreMunicipio', upper('NombreMunicipio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------------+\n",
      "|CodigoDepartamento|CodigoMunicipio|CodigoCentroPoblado|NombreDepartamento|NombreMunicipio| NombreCentroPoblado| TipoCentroPoblado|      Longitud|      Latitud|Nombre Distrito|Municipio/AreasNoMunicipalizadas(ANM)|NombreAreaMetropolitana|\n",
      "+------------------+---------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------------+\n",
      "|                18|          18460|           18460000|           CAQUETA|        CAQUETA|               MILÁN|CABECERA MUNICIPAL| -75.506962028|1.29042720175|           null|                            MUNICIPIO|                   null|\n",
      "|                52|          52835|           52835161|            NARIÑO|         NARIÑO|        PIÑAL SALADO|    CENTRO POBLADO|-78.7116527073|1.70135268948|           null|                            MUNICIPIO|                   null|\n",
      "|                52|          52473|           52473001|            NARIÑO|         NARIÑO|COCALITO JIMÉNEZ ...|    CENTRO POBLADO|-78.5337180148|2.45016569889|           null|                            MUNICIPIO|                   null|\n",
      "|                19|          19698|           19698001|             CAUCA|          CAUCA|           EL PALMAR|    CENTRO POBLADO|-76.5279078588|2.99973361941|           null|                            MUNICIPIO|                   null|\n",
      "|                76|          76130|           76130023|   VALLE DEL CAUCA|VALLE DEL CAUCA|          TRES TUSAS|    CENTRO POBLADO|-76.3456900461|3.33130571679|           null|                            MUNICIPIO|                   null|\n",
      "+------------------+---------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departamentos.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------------+------------+----------+-------+----------------+\n",
      "|CodigoDepartamento|ID_Municipio_T|CodigoCentroPoblado|NombreDepartamento|NombreMunicipio| NombreCentroPoblado| TipoCentroPoblado|      Longitud|      Latitud|Nombre Distrito|Municipio/AreasNoMunicipalizadas(ANM)|NombreAreaMetropolitana|FechaInicial|FechaFinal|Version|ID_Municipio_DWH|\n",
      "+------------------+--------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------------+------------+----------+-------+----------------+\n",
      "|                18|         18460|           18460000|           CAQUETA|        CAQUETA|               MILÁN|CABECERA MUNICIPAL| -75.506962028|1.29042720175|           null|                            MUNICIPIO|                   null|  2005-01-01|2199-12-31|      1|               1|\n",
      "|                52|         52835|           52835161|            NARIÑO|         NARIÑO|        PIÑAL SALADO|    CENTRO POBLADO|-78.7116527073|1.70135268948|           null|                            MUNICIPIO|                   null|  2005-01-01|2199-12-31|      1|               2|\n",
      "|                52|         52473|           52473001|            NARIÑO|         NARIÑO|COCALITO JIMÉNEZ ...|    CENTRO POBLADO|-78.5337180148|2.45016569889|           null|                            MUNICIPIO|                   null|  2005-01-01|2199-12-31|      1|               3|\n",
      "|                19|         19698|           19698001|             CAUCA|          CAUCA|           EL PALMAR|    CENTRO POBLADO|-76.5279078588|2.99973361941|           null|                            MUNICIPIO|                   null|  2005-01-01|2199-12-31|      1|               4|\n",
      "|                76|         76130|           76130023|   VALLE DEL CAUCA|VALLE DEL CAUCA|          TRES TUSAS|    CENTRO POBLADO|-76.3456900461|3.33130571679|           null|                            MUNICIPIO|                   null|  2005-01-01|2199-12-31|      1|               5|\n",
      "+------------------+--------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------------+------------+----------+-------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departamentosNuevo = departamentos.withColumn('FechaInicial',lit('2005-01-01'))\n",
    "departamentosNuevo = departamentosNuevo.withColumn('FechaFinal',lit('2199-12-31'))\n",
    "departamentosNuevo = departamentosNuevo.withColumn('Version', lit(1))\n",
    "departamentosNuevo = departamentosNuevo.withColumnRenamed(\"CodigoMunicipio\",\"ID_Municipio_T\")\n",
    "departamentosNuevo = departamentosNuevo.withColumn('ID_Municipio_DWH', f.monotonically_increasing_id() + 1)\n",
    "departamentosNuevo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------+------------+----------+-------+----------------+\n",
      "|CodigoDepartamento|ID_Municipio_T|CodigoCentroPoblado|NombreDepartamento|NombreMunicipio| NombreCentroPoblado| TipoCentroPoblado|      Longitud|      Latitud|Nombre Distrito|Municipio/AreasNoMunicipalizadas(ANM)|AreaMetropolitana|FechaInicial|FechaFinal|Version|ID_Municipio_DWH|\n",
      "+------------------+--------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------+------------+----------+-------+----------------+\n",
      "|                18|         18460|           18460000|           CAQUETA|        CAQUETA|               MILÁN|CABECERA MUNICIPAL| -75.506962028|1.29042720175|        missing|                            MUNICIPIO|          missing|  2005-01-01|2199-12-31|      1|               1|\n",
      "|                52|         52835|           52835161|            NARIÑO|         NARIÑO|        PIÑAL SALADO|    CENTRO POBLADO|-78.7116527073|1.70135268948|        missing|                            MUNICIPIO|          missing|  2005-01-01|2199-12-31|      1|               2|\n",
      "|                52|         52473|           52473001|            NARIÑO|         NARIÑO|COCALITO JIMÉNEZ ...|    CENTRO POBLADO|-78.5337180148|2.45016569889|        missing|                            MUNICIPIO|          missing|  2005-01-01|2199-12-31|      1|               3|\n",
      "|                19|         19698|           19698001|             CAUCA|          CAUCA|           EL PALMAR|    CENTRO POBLADO|-76.5279078588|2.99973361941|        missing|                            MUNICIPIO|          missing|  2005-01-01|2199-12-31|      1|               4|\n",
      "|                76|         76130|           76130023|   VALLE DEL CAUCA|VALLE DEL CAUCA|          TRES TUSAS|    CENTRO POBLADO|-76.3456900461|3.33130571679|        missing|                            MUNICIPIO|          missing|  2005-01-01|2199-12-31|      1|               5|\n",
      "+------------------+--------------+-------------------+------------------+---------------+--------------------+------------------+--------------+-------------+---------------+-------------------------------------+-----------------+------------+----------+-------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departamentosNuevo = departamentosNuevo.fillna({'Nombre Distrito':'missing'})\n",
    "departamentosNuevo = departamentosNuevo.fillna({'NombreAreaMetropolitana':'missing'})\n",
    "departamentosNuevo = departamentosNuevo.withColumnRenamed(\"NombreAreaMetropolitana\", \"AreaMetropolitana\")\n",
    "departamentosNuevo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "departamentosOriginal = departamentos.fillna({'Nombre Distrito':'missing'})\n",
    "departamentosOriginal = departamentosOriginal.fillna({'NombreAreaMetropolitana':'missing'})\n",
    "departamentosOriginal = departamentosOriginal.withColumnRenamed(\"NombreAreaMetropolitana\", \"AreaMetropolitana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparar nombre de los departamentos usando diccionario y codigo departamento generado de divipola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "departamentosDic = {15:'BOYACA', 54:'NORTE DE SANTANDER', 94:'GUAINIA', 73:'TOLIMA', 50:'META', 66:'RISARALDA', 47:'MAGDALENA', 85:'CASANARE', 91:'AMAZONAS', 11:'BOGOTA, DISTRITO CAPITAL', 95:'GUAVIARE', 25:'CUNDINAMARCA', 88:'ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA', 76:'VALLE DEL CAUCA', 99:'VICHADA', 68:'SANTANDER', 27:'CHOCO', 86:'PUTUMAYO', 70:'SUCRE', 5:'ANTIOQUIA', 19:'CAUCA', 81:'ARAUCA', 13:'BOLIVAR', 41:'HUILA', 17:'CALDAS', 63:'QUINDIO', 97:'VAUPES', 20:'CESAR', 52:'NARIÑO', 23:'CORDOBA', 44:'LA GUAJIRA', 8:'ATLANTICO', 18:'CAQUETA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pibFixed = pib.withColumn(\"DEPARTAMENTOS_FIXED\", f.udf(lambda dep_code: departamentosDic.get(dep_code, \"missing\"), t.StringType())(f.col('CodigoDepartamento(DIVIPOLA)')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pibFixed = pibFixed.withColumn(\"DEPARTAMENTOS\", col(\"DEPARTAMENTOS_FIXED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pibFixed = pibFixed.drop(\"DEPARTAMENTOS_FIXED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------+-------+-------+------------------+-----------------+-------+-------+-----------------+-------+-------+-------+-------+-------+-------+\n",
      "|CodigoDepartamento(DIVIPOLA)|     DEPARTAMENTOS|   2006|   2007|              2008|             2010|   2011|   2012|             2013|   2014|   2015|   2016|   2017|   2009|   2005|\n",
      "+----------------------------+------------------+-------+-------+------------------+-----------------+-------+-------+-----------------+-------+-------+-------+-------+-------+-------+\n",
      "|                          47|         MAGDALENA|4202994|4618524| 5293554.101685749|6119382.927756879|6441145|6942728|7530341.883201833|7620221|8285062|9081224|9488025|5858657|3938108|\n",
      "|                          54|NORTE DE SANTANDER|4562230|5093601| 5756904.272168976|6377160.081745004|6845992|7152319|7716659.361075875|8310220|8890010|9693223|9984804|6139384|3928796|\n",
      "|                          18|           CAQUETA|3575615|4060678| 4519574.129383702|5048396.606737779|5516404|6476778| 7161524.44383983|7990249|8401448|9164641|9639203|4901195|3306217|\n",
      "|                          99|           VICHADA|4114080|4091512|  4337203.79854487|4285403.948100506|4377994|4639459|4856888.325019439|4733848|5271600|5586503|5677781|4390230|3887315|\n",
      "|                          27|             CHOCO|3314596|3497940|3822819.1728744935|6317316.431162511|7769706|7400499|6282262.504550394|6291011|7011686|8146211|7511347|4690095|3060247|\n",
      "+----------------------------+------------------+-------+-------+------------------+-----------------+-------+-------+-----------------+-------+-------+-------+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pibFixed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan duplicados totales de pib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 28)\n"
     ]
    }
   ],
   "source": [
    "print((pibFixed.count(),pibFixed.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pibFixed = pibFixed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print((pibFixed.count(),pibFixed.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear nueva columna año y setiar a cada fila de datos su correspondiente año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pibFixedInt = pibFixed.withColumn(\"2005\", floor(col(\"2005\"))) \\\n",
    "             .withColumn(\"2006\", floor(col(\"2006\"))) \\\n",
    "             .withColumn(\"2007\", floor(col(\"2007\"))) \\\n",
    "             .withColumn(\"2008\", floor(col(\"2008\"))) \\\n",
    "             .withColumn(\"2009\", floor(col(\"2009\"))) \\\n",
    "             .withColumn(\"2010\", floor(col(\"2010\"))) \\\n",
    "             .withColumn(\"2011\", floor(col(\"2011\"))) \\\n",
    "             .withColumn(\"2012\", floor(col(\"2012\"))) \\\n",
    "             .withColumn(\"2013\", floor(col(\"2013\"))) \\\n",
    "             .withColumn(\"2014\", floor(col(\"2014\"))) \\\n",
    "             .withColumn(\"2015\", floor(col(\"2015\"))) \\\n",
    "             .withColumn(\"2016\", floor(col(\"2016\"))) \\\n",
    "             .withColumn(\"2017\", floor(col(\"2017\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear traspuesto\n",
    "pibTraspuesto = pibFixedInt.withColumn(\n",
    "    \"year_value\",\n",
    "    array(\n",
    "        struct(lit(\"2005\").alias(\"year\"), col(\"2005\").alias(\"value\")),\n",
    "        struct(lit(\"2006\").alias(\"year\"), col(\"2006\").alias(\"value\")),\n",
    "        struct(lit(\"2007\").alias(\"year\"), col(\"2007\").alias(\"value\")),\n",
    "        struct(lit(\"2008\").alias(\"year\"), col(\"2008\").alias(\"value\")),\n",
    "        struct(lit(\"2009\").alias(\"year\"), col(\"2009\").alias(\"value\")),\n",
    "        struct(lit(\"2010\").alias(\"year\"), col(\"2010\").alias(\"value\")),\n",
    "        struct(lit(\"2011\").alias(\"year\"), col(\"2011\").alias(\"value\")),\n",
    "        struct(lit(\"2012\").alias(\"year\"), col(\"2012\").alias(\"value\")),\n",
    "        struct(lit(\"2013\").alias(\"year\"), col(\"2013\").alias(\"value\")),\n",
    "        struct(lit(\"2014\").alias(\"year\"), col(\"2014\").alias(\"value\")),\n",
    "        struct(lit(\"2015\").alias(\"year\"), col(\"2015\").alias(\"value\")),\n",
    "        struct(lit(\"2016\").alias(\"year\"), col(\"2016\").alias(\"value\")),\n",
    "        struct(lit(\"2017\").alias(\"year\"), col(\"2017\").alias(\"value\"))\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode al array\n",
    "df_long = pibTraspuesto.withColumn(\"year_value\", explode(col(\"year_value\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar and renombrar columnas\n",
    "df_pib_final = df_long.select(\n",
    "    col(\"CodigoDepartamento(DIVIPOLA)\").alias(\"DP\"),\n",
    "    col(\"DEPARTAMENTOS\"),\n",
    "    col(\"year_value.year\").alias(\"AÑO\"),\n",
    "    col(\"year_value.value\").alias(\"PIB\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pibCleaned = df_pib_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----+-------+\n",
      "| DP|DEPARTAMENTOS| AÑO|    PIB|\n",
      "+---+-------------+----+-------+\n",
      "| 63|      QUINDIO|2005|5378939|\n",
      "| 63|      QUINDIO|2006|6350376|\n",
      "| 63|      QUINDIO|2007|6908084|\n",
      "| 63|      QUINDIO|2008|7449000|\n",
      "| 63|      QUINDIO|2009|7790106|\n",
      "+---+-------------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pibCleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proyecciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan duplicados totales de proyecciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2574, 1287)\n"
     ]
    }
   ],
   "source": [
    "print((proyecciones.count(),proyecciones.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyecciones = proyecciones.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1287, 1287)\n"
     ]
    }
   ],
   "source": [
    "print((proyecciones.count(),proyecciones.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan dos ecuaciones para interpolar proyecciones atipicas:\n",
    "\n",
    "Total hombres DP=76 Valor atipico año 2016\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= 11116854.003*ln(x) -82472192.439\n",
    "\\end{align}\n",
    "$$\n",
    "Total mujeres DP=99  Valor atipico año 2009\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= 1137.848x - 3346260\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar valores invalidos y atipicos hombres 2016 DP=76 y mujeres 2014 DP = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMACION\n",
    "hombresIncorrecto = proyecciones.filter((col('AÑO')==2016)).filter((col('DP') == 76)).filter(col('AREA GEOGRAFICA')==\"Total\")\n",
    "hombresCorrecto = proyecciones.filter((col('AÑO')!=2016) | (col('DP') != 76) | (col('AREA GEOGRAFICA')!=\"Total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287\n",
      "1\n",
      "1286\n"
     ]
    }
   ],
   "source": [
    "print(proyecciones.count())\n",
    "print(hombresIncorrecto.count())\n",
    "print(hombresCorrecto.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombresIncorrecto = hombresIncorrecto.withColumn(\"Total Hombres Fixed\", f.udf(lambda anio: math.ceil(11116854.0030*math.log(anio)-82472192.43), t.IntegerType())(f.col('AÑO')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombresIncorrecto = hombresIncorrecto.withColumn(\"Total Hombres\", col(\"Total Hombres Fixed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombresIncorrecto = hombresIncorrecto.drop(\"Total Hombres Fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombresIncorrecto = hombresIncorrecto.union(hombresCorrecto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1287"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hombresIncorrecto.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyeccionFixed = hombresIncorrecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRANSFORMACION\n",
    "mujeresIncorrecto = proyeccionFixed.filter((col('AÑO')==2009)).filter((col('DP') == 99)).filter(col('AREA GEOGRAFICA')==\"Total\")\n",
    "mujeresCorrecto = proyeccionFixed.filter((col('AÑO')!=2009) | (col('DP') != 99) | (col('AREA GEOGRAFICA')!=\"Total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287\n",
      "1\n",
      "1286\n"
     ]
    }
   ],
   "source": [
    "print(proyecciones.count())\n",
    "print(mujeresIncorrecto.count())\n",
    "print(mujeresCorrecto.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1287"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mujeresIncorrecto = mujeresIncorrecto.withColumn(\"Total Mujeres Fixed\", f.udf(lambda anio: math.ceil(1137.848*anio-2246260.863), t.IntegerType())(f.col('AÑO')))\n",
    "mujeresIncorrecto = mujeresIncorrecto.withColumn(\"Total Mujeres\", col(\"Total Mujeres Fixed\"))\n",
    "mujeresIncorrecto = mujeresIncorrecto.drop(\"Total Mujeres Fixed\")\n",
    "mujeresIncorrecto = mujeresIncorrecto.union(mujeresCorrecto)\n",
    "mujeresIncorrecto.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyeccionFixed = mujeresIncorrecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyeccionFixed = proyeccionFixed.filter(col('AREA GEOGRAFICA')==\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsRemove = ()\n",
    "colsList = list(colsRemove)\n",
    "for n in range(100):\n",
    "    colsList.append(\"Hombres_\"+ str(n))\n",
    "    colsList.append(\"Mujeres_\"+ str(n))\n",
    "    colsList.append(\"Total_\"+ str(n))\n",
    "colsList.append(\"Hombres_100 y más\")\n",
    "colsList.append(\"Mujeres_100 y más\")\n",
    "colsList.append(\"Total_100 y más\")\n",
    "colsRemove = tuple(colsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyeccionCleaned = proyeccionFixed.drop(*colsRemove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyeccionCleaned = proyeccionCleaned.withColumnRenamed(\"Total Hombres\", \"TotalHombres\")\n",
    "proyeccionCleaned = proyeccionCleaned.withColumnRenamed(\"Total Mujeres\", \"TotalMujeres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+----+---------------+------------+------------+-------+\n",
      "| DP|          DPNOM| AÑO|AREA GEOGRAFICA|TotalHombres|TotalMujeres|  Total|\n",
      "+---+---------------+----+---------------+------------+------------+-------+\n",
      "| 99|        vichada|2009|          Total|       47300|       39676|  86991|\n",
      "| 76|valle del cauca|2016|          Total|     2114512|     2304500|4414569|\n",
      "| 19|          cauca|2011|          Total|      679140|      687618|1366758|\n",
      "| 41|          huila|2008|          Total|      488493|      489035| 977528|\n",
      "| 44|     la guajira|2010|          Total|      352424|      370489| 722913|\n",
      "+---+---------------+----+---------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proyeccionCleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union tablas primera version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pib2005 = pibCleaned.filter((col('AÑO')==2005))\n",
    "proyeccion2005 = proyeccionCleaned.filter((col('AÑO')==2005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "geografiaConDemografia = departamentosNuevo.alias('dep').join(proyeccion2005.alias('proy'),departamentosNuevo.CodigoDepartamento == proyeccion2005.DP,'left_outer')\\\n",
    "                    .join(pib2005.alias('pib'),departamentosNuevo.CodigoDepartamento == pib2005.DP,'left_outer') \\\n",
    "                    .select([col('dep.ID_Municipio_DWH'),col('dep.ID_Municipio_T'),col('dep.NombreMunicipio'),\n",
    "                                         col('dep.NombreDepartamento'),col('dep.AreaMetropolitana'),col('dep.Longitud'),col('dep.Latitud'),\n",
    "                                         col('pib.PIB'),col('proy.TotalHombres'),col('proy.TotalMujeres'),\n",
    "                             col('dep.FechaInicial'), col('dep.FechaFinal'), col('dep.Version')]) \\\n",
    "                                .fillna({'PIB': 0, 'TotalHombres': 0, 'TotalMujeres': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+---------------+------------------+-----------------+--------------+-------------+-------+------------+------------+------------+----------+-------+\n",
      "|ID_Municipio_DWH|ID_Municipio_T|NombreMunicipio|NombreDepartamento|AreaMetropolitana|      Longitud|      Latitud|    PIB|TotalHombres|TotalMujeres|FechaInicial|FechaFinal|Version|\n",
      "+----------------+--------------+---------------+------------------+-----------------+--------------+-------------+-------+------------+------------+------------+----------+-------+\n",
      "|               1|         18460|        CAQUETA|           CAQUETA|          missing| -75.506962028|1.29042720175|3306217|      194127|      185146|  2005-01-01|2199-12-31|      1|\n",
      "|               2|         52835|         NARIÑO|            NARIÑO|          missing|-78.7116527073|1.70135268948|      0|      746790|      763664|  2005-01-01|2199-12-31|      1|\n",
      "|               3|         52473|         NARIÑO|            NARIÑO|          missing|-78.5337180148|2.45016569889|      0|      746790|      763664|  2005-01-01|2199-12-31|      1|\n",
      "|               4|         19698|          CAUCA|             CAUCA|          missing|-76.5279078588|2.99973361941|      0|      637000|      644052|  2005-01-01|2199-12-31|      1|\n",
      "|               5|         76130|VALLE DEL CAUCA|   VALLE DEL CAUCA|          missing|-76.3456900461|3.33130571679|8233652|     2045007|     2161944|  2005-01-01|2199-12-31|      1|\n",
      "+----------------+--------------+---------------+------------------+-----------------+--------------+-------------+-------+------------+------------+------------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "geografiaConDemografia.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, geografiaConDemografia,'Proyecto_G5_202413.geografiaConDemografia_Test', db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de historia GeografiaConDemografia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+---------------+------------------+-----------------+--------------+-------------+-------+------------+------------+------------+----------+-------+\n",
      "|ID_Municipio_DWH|ID_Municipio_T|NombreMunicipio|NombreDepartamento|AreaMetropolitana|Longitud      |Latitud      |PIB    |TotalHombres|TotalMujeres|FechaInicial|FechaFinal|Version|\n",
      "+----------------+--------------+---------------+------------------+-----------------+--------------+-------------+-------+------------+------------+------------+----------+-------+\n",
      "|1               |18460         |CAQUETA        |CAQUETA           |missing          |-75.506962028 |1.29042720175|3306217|194127      |185146      |2005-01-01  |2005-12-31|1      |\n",
      "|2               |52835         |NARIÑO         |NARIÑO            |missing          |-78.7116527073|1.70135268948|0      |746790      |763664      |2005-01-01  |2005-12-31|1      |\n",
      "|3               |52473         |NARIÑO         |NARIÑO            |missing          |-78.5337180148|2.45016569889|0      |746790      |763664      |2005-01-01  |2005-12-31|1      |\n",
      "|4               |19698         |CAUCA          |CAUCA             |missing          |-76.5279078588|2.99973361941|0      |637000      |644052      |2005-01-01  |2005-12-31|1      |\n",
      "|5               |76130         |VALLE DEL CAUCA|VALLE DEL CAUCA   |missing          |-76.3456900461|3.33130571679|8233652|2045007     |2161944     |2005-01-01  |2005-12-31|1      |\n",
      "|6               |94886         |GUAINIA        |GUAINIA           |missing          |-67.3311752463|3.36409215313|4134059|16471       |14260       |2005-01-01  |2005-12-31|1      |\n",
      "|7               |76109         |VALLE DEL CAUCA|VALLE DEL CAUCA   |missing          |-77.3566075637|3.36668844372|8233652|2045007     |2161944     |2005-01-01  |2005-12-31|1      |\n",
      "|8               |76233         |VALLE DEL CAUCA|VALLE DEL CAUCA   |missing          |-76.7124983852|3.580820184  |8233652|2045007     |2161944     |2005-01-01  |2005-12-31|1      |\n",
      "|9               |63190         |QUINDIO        |QUINDIO           |missing          |-75.6987236297|4.56198068286|5378939|250376      |260805      |2005-01-01  |2005-12-31|1      |\n",
      "|10              |73043         |TOLIMA         |TOLIMA            |missing          |-75.0943785124|4.57984363877|5905371|647256      |656960      |2005-01-01  |2005-12-31|1      |\n",
      "|11              |63690         |QUINDIO        |QUINDIO           |missing          |-75.6173359378|4.61872337139|5378939|250376      |260805      |2005-01-01  |2005-12-31|1      |\n",
      "|12              |66075         |RISARALDA      |RISARALDA         |missing          |-75.9615338152|4.96303410744|6277539|431999      |445975      |2005-01-01  |2005-12-31|1      |\n",
      "|13              |73055         |TOLIMA         |TOLIMA            |missing          |-74.9937663072|4.98901914382|5905371|647256      |656960      |2005-01-01  |2005-12-31|1      |\n",
      "|14              |27205         |CHOCO          |CHOCO             |missing          |-76.5225860054|5.10715851515|3060247|196043      |206666      |2005-01-01  |2005-12-31|1      |\n",
      "|15              |15822         |BOYACA         |BOYACA            |missing          |-72.9858981444|5.56049737415|7211579|557351      |583314      |2005-01-01  |2005-12-31|1      |\n",
      "|16              |15820         |BOYACA         |BOYACA            |missing          |-72.8647798524|5.7681752377 |7211579|557351      |583314      |2005-01-01  |2005-12-31|1      |\n",
      "|17              |15238         |BOYACA         |BOYACA            |missing          |-73.0129629707|5.81810953583|7211579|557351      |583314      |2005-01-01  |2005-12-31|1      |\n",
      "|18              |68298         |SANTANDER      |SANTANDER         |missing          |-73.3848593475|5.86742319293|9951651|920224      |962151      |2005-01-01  |2005-12-31|1      |\n",
      "|19              |68377         |SANTANDER      |SANTANDER         |missing          |-74.0571993826|5.88969352654|9951651|920224      |962151      |2005-01-01  |2005-12-31|1      |\n",
      "|20              |68773         |SANTANDER      |SANTANDER         |missing          |-73.9554106133|5.94003177315|9951651|920224      |962151      |2005-01-01  |2005-12-31|1      |\n",
      "+----------------+--------------+---------------+------------------+-----------------+--------------+-------------+-------+------------+------------+------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  DataFrame Inicial\n",
    "geografiaConDemografiaInitial = geografiaConDemografia\n",
    "\n",
    "# maximum ID_Municipio_DWH y version from del DataFrame original\n",
    "max_id_dwh = geografiaConDemografiaInitial.agg(spark_max(\"ID_Municipio_DWH\")).collect()[0][0]\n",
    "max_version = geografiaConDemografiaInitial.agg(spark_max(\"Version\")).collect()[0][0]\n",
    "\n",
    "# Actualizar fechaFinal de DF original a 2005-12-31\n",
    "geografiaConDemografiaInitial = geografiaConDemografiaInitial.withColumn(\"FechaFinal\", lit(\"2005-12-31\"))\n",
    "\n",
    "initialYear = 2006\n",
    "endYear = 2017\n",
    "\n",
    "#def return_end_year(year: int):\n",
    "#    if year < endYear:\n",
    "#        return lit(f\"{year}-12-31\")\n",
    "#    else:\n",
    "#        return lit(\"2199-12-31\")\n",
    "# Funcion para crear un nuevo DF with ID_Municipio_DWH y version actualizados\n",
    "def create_new_df(df_new_base: DataFrame, max_id_dwh: int, max_version: int, year: int):\n",
    "    df_new_updated = df_new_base.withColumn(\"ID_Municipio_DWH\", col(\"ID_Municipio_T\") + max_id_dwh) \\\n",
    "        .withColumn(\"FechaInicial\", lit(f\"{year}-01-01\")) \\\n",
    "        .withColumn(\"FechaFinal\", lit(f\"{year}-12-31\") if year < endYear else lit(\"2199-12-31\")) \\\n",
    "        .withColumn(\"Version\", lit(max_version + 1))\n",
    "    return df_new_updated\n",
    "\n",
    "initialYear = 2006\n",
    "endYear = 2017\n",
    "for n in range(12):\n",
    "    # Crear DF para el año\n",
    "    pibN = pibCleaned.filter((col('AÑO')==initialYear+n))\n",
    "    proyeccionN = proyeccionCleaned.filter((col('AÑO')==initialYear+n))\n",
    "\n",
    "    geografiaConDemografiaN = departamentosNuevo.alias('dep').join(proyeccionN.alias('proy'),departamentosNuevo.CodigoDepartamento == proyeccionN.DP,'left_outer')\\\n",
    "                    .join(pibN.alias('pib'),departamentosNuevo.CodigoDepartamento == pibN.DP,'left_outer') \\\n",
    "                    .select([col('dep.ID_Municipio_T'),col('dep.NombreMunicipio'),\n",
    "                                         col('dep.NombreDepartamento'),col('dep.AreaMetropolitana'),col('dep.Longitud'),col('dep.Latitud'),\n",
    "                                         col('pib.PIB'),col('proy.TotalHombres'),col('proy.TotalMujeres')]) \\\n",
    "                                .fillna({'PIB': 0, 'TotalHombres': 0, 'TotalMujeres': 0})\n",
    "    \n",
    "    df_new = create_new_df(geografiaConDemografiaN, max_id_dwh, max_version, initialYear+n)\n",
    "    geografiaConDemografiaInitial = geografiaConDemografiaInitial.unionByName(df_new)\n",
    "\n",
    "    # actualizar max_id_dwh and max_version\n",
    "    max_id_dwh += geografiaConDemografiaN.count()\n",
    "    max_version += 1\n",
    "\n",
    "\n",
    "# Show the result\n",
    "geografiaConDemografiaInitial.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, geografiaConDemografiaInitial,'Proyecto_G5_202413.G5_GeografiaConDemografia', db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #6: Dimensión Fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso aplicaremos ETL a la **Dimension Fecha**, su fuente de datos viene de la tabla Vuelos y Aeropuertos de la base de datos de ProyectoTransaccional.\n",
    "\n",
    "Al final del proceso de ETL se espera obtener una nueva tabla llamada G5_Fecha en la base de datos de Proyecto_G5_202413 conteniendo las siguiente columnas:\n",
    "\n",
    "* idFecha\n",
    "* descripcion\n",
    "* Mes\n",
    "* Anio\n",
    "* Dia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraccion\n",
    "En esta seccion obtendremos los datos de las fuentes identificadas en nuestro diseño.\n",
    "\n",
    "T1. Se crea un dataframe que contiene unicamente la columna fecha_construccion de la tabla aeropuertos y eliminar registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de Registros de la tabla Vuelos obtenidos fueron: 213\n",
      "El dataFrame extraido queda de la siguiente forma:\n",
      "+----------+\n",
      "|     fecha|\n",
      "+----------+\n",
      "|2015-06-05|\n",
      "|2013-04-26|\n",
      "|2009-05-07|\n",
      "|2013-11-19|\n",
      "|2013-03-20|\n",
      "|2014-11-11|\n",
      "|2012-10-25|\n",
      "|2009-10-06|\n",
      "|2012-08-16|\n",
      "|2013-05-16|\n",
      "|2014-02-28|\n",
      "|2013-05-03|\n",
      "|2013-12-05|\n",
      "|2013-07-24|\n",
      "|2010-08-19|\n",
      "|2015-01-27|\n",
      "|2013-09-24|\n",
      "|2014-12-15|\n",
      "|2014-01-21|\n",
      "|2014-01-31|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_aeropuertos_fc = '''(SELECT DISTINCT fecha_construccion AS fecha FROM ProyectoTransaccional.aeropuertos) AS Temp_aeropuertos_fc'''\n",
    "aeropuertos_fc_df = obtener_dataframe_de_bd(source_db_connection_string, sql_aeropuertos_fc, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de Registros de la tabla Vuelos obtenidos fueron: ' + str(aeropuertos_fc_df.count()))\n",
    "print('El dataFrame extraido queda de la siguiente forma:')\n",
    "aeropuertos_fc_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T2. Se crea un dataframe que contiene unicamente la columna fecha_vigencia de la tabla aeropuertos y eliminar registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de Registros de la tabla Vuelos obtenidos fueron: 85\n",
      "El dataFrame extraido queda de la siguiente forma:\n",
      "+----------+\n",
      "|     fecha|\n",
      "+----------+\n",
      "|2018-06-11|\n",
      "|2016-05-07|\n",
      "|          |\n",
      "|2015-11-07|\n",
      "|2017-03-03|\n",
      "|2016-05-10|\n",
      "|2016-08-01|\n",
      "|2018-02-06|\n",
      "|2017-12-01|\n",
      "|2018-03-05|\n",
      "|2015-12-03|\n",
      "|2017-01-09|\n",
      "|2017-07-09|\n",
      "|2017-11-05|\n",
      "|2017-12-02|\n",
      "|2015-10-10|\n",
      "|2016-11-12|\n",
      "|2016-05-09|\n",
      "|2017-06-11|\n",
      "|2015-10-09|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_aeropuertos_fv = '''(SELECT DISTINCT fecha_vigencia AS fecha FROM ProyectoTransaccional.aeropuertos) AS Temp_aeropuertos_fc'''\n",
    "aeropuertos_fv_df = obtener_dataframe_de_bd(source_db_connection_string, sql_aeropuertos_fv, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de Registros de la tabla Vuelos obtenidos fueron: ' + str(aeropuertos_fv_df.count()))\n",
    "print('El dataFrame extraido queda de la siguiente forma:')\n",
    "aeropuertos_fv_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3. Se crea un dataframe que contiene unicamente la columna ano, mes de la tabla vuelos y eliminar registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de Registros de la tabla Vuelos obtenidos fueron: 563265\n",
      "El dataFrame extraido queda de la siguiente forma:\n",
      "+----+---+\n",
      "| ano|mes|\n",
      "+----+---+\n",
      "|2012|  9|\n",
      "|2012| 11|\n",
      "|2012| 12|\n",
      "|2012| 11|\n",
      "|2012|  1|\n",
      "|2012|  2|\n",
      "|2004|  1|\n",
      "|2012|  3|\n",
      "|2004|  2|\n",
      "|2012|  4|\n",
      "|2004|  3|\n",
      "|2012|  5|\n",
      "|2004|  4|\n",
      "|2012|  6|\n",
      "|2004|  5|\n",
      "|2012|  7|\n",
      "|2004|  6|\n",
      "|2012|  8|\n",
      "|2004|  7|\n",
      "|2012| 10|\n",
      "+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_vuelos_fecha = '''(SELECT  ano, mes FROM ProyectoTransaccional.vuelos) AS Temp_vuelos_trafico'''\n",
    "vuelos_fecha_df = obtener_dataframe_de_bd(source_db_connection_string, sql_vuelos_fecha, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de Registros de la tabla Vuelos obtenidos fueron: ' + str(vuelos_fecha_df.count()))\n",
    "print('El dataFrame extraido queda de la siguiente forma:')\n",
    "vuelos_fecha_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de duplicados totales es de 563097\n",
      "Dataframe sin duplicados\n",
      "+----+---+\n",
      "| ano|mes|\n",
      "+----+---+\n",
      "|2012| 10|\n",
      "|2005|  5|\n",
      "|2007|  6|\n",
      "|2010|  7|\n",
      "|2010| 12|\n",
      "|2015|  2|\n",
      "|2017|  3|\n",
      "|2008|  8|\n",
      "|2017|  8|\n",
      "|2004|  6|\n",
      "|2014|  4|\n",
      "|2009| 11|\n",
      "|2005| 10|\n",
      "|2017| 10|\n",
      "|2015| 12|\n",
      "|2016|  7|\n",
      "|2004|  8|\n",
      "|2016| 11|\n",
      "|2012|  8|\n",
      "|2013|  2|\n",
      "+----+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "Cantidad Final: 168\n"
     ]
    }
   ],
   "source": [
    "# Eliminar duplicados\n",
    "duplicates_vuelos_fecha = vuelos_fecha_df.count() - vuelos_fecha_df.distinct().count()\n",
    "vuelos_fecha_df_whitout_duplicates = vuelos_fecha_df.distinct()\n",
    "print('La cantidad de duplicados totales es de ' + str(duplicates_vuelos_fecha))\n",
    "print('Dataframe sin duplicados')\n",
    "vuelos_fecha_df_whitout_duplicates.show()\n",
    "print('Cantidad Final: '+str(vuelos_fecha_df_whitout_duplicates.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|mes|NewMes|\n",
      "+---+------+\n",
      "|  1|    01|\n",
      "|  2|    02|\n",
      "|  3|    03|\n",
      "|  4|    04|\n",
      "|  5|    05|\n",
      "|  6|    06|\n",
      "|  7|    07|\n",
      "|  8|    08|\n",
      "|  9|    09|\n",
      "| 10|    10|\n",
      "| 11|    11|\n",
      "| 12|    12|\n",
      "+---+------+\n",
      "\n",
      "+---+----+---+------+\n",
      "|mes| ano|dia|NewMes|\n",
      "+---+----+---+------+\n",
      "|  1|2017| 01|    01|\n",
      "|  1|2010| 01|    01|\n",
      "|  1|2011| 01|    01|\n",
      "|  1|2015| 01|    01|\n",
      "|  1|2013| 01|    01|\n",
      "|  1|2004| 01|    01|\n",
      "|  1|2006| 01|    01|\n",
      "|  1|2012| 01|    01|\n",
      "|  1|2016| 01|    01|\n",
      "|  1|2005| 01|    01|\n",
      "|  1|2014| 01|    01|\n",
      "|  1|2009| 01|    01|\n",
      "|  1|2008| 01|    01|\n",
      "|  1|2007| 01|    01|\n",
      "|  3|2016| 01|    03|\n",
      "|  3|2007| 01|    03|\n",
      "|  3|2004| 01|    03|\n",
      "|  3|2012| 01|    03|\n",
      "|  3|2008| 01|    03|\n",
      "|  3|2006| 01|    03|\n",
      "+---+----+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creamos DF con el diccionario auxiliar\n",
    "df_dic_fecha = pd.DataFrame({'mes': ['1','2','3','4','5','6','7','8','9','10','11','12'], 'NewMes': ['01', '02', '03','04','05','06','07','08','09','10','11','12']})\n",
    "#mostrar DatraFrame\n",
    "diccionarioFecha=spark.createDataFrame(df_dic_fecha)\n",
    "diccionarioFecha.show()\n",
    "# Se agrega columna dia con valor 01 indicado por el negocio \n",
    "vuelos_fecha_df_whitout_duplicates = vuelos_fecha_df_whitout_duplicates.coalesce(1).withColumn(\"dia\",f.lit('01').alias('dia'))\n",
    "\n",
    "# Creamos un join con el diccionario \n",
    "vuelos_fecha_df_whitout_duplicates = vuelos_fecha_df_whitout_duplicates.join(diccionarioFecha,how = 'inner',  on='mes')\n",
    "# Mostramos el resultado del join con diccionario fecha\n",
    "vuelos_fecha_df_whitout_duplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+------+----------+\n",
      "|mes| ano|dia|NewMes|     fecha|\n",
      "+---+----+---+------+----------+\n",
      "|  1|2017| 01|    01|2017-01-01|\n",
      "|  1|2010| 01|    01|2010-01-01|\n",
      "|  1|2011| 01|    01|2011-01-01|\n",
      "|  1|2015| 01|    01|2015-01-01|\n",
      "|  1|2013| 01|    01|2013-01-01|\n",
      "|  1|2004| 01|    01|2004-01-01|\n",
      "|  1|2006| 01|    01|2006-01-01|\n",
      "|  1|2012| 01|    01|2012-01-01|\n",
      "|  1|2016| 01|    01|2016-01-01|\n",
      "|  1|2005| 01|    01|2005-01-01|\n",
      "|  1|2014| 01|    01|2014-01-01|\n",
      "|  1|2009| 01|    01|2009-01-01|\n",
      "|  1|2008| 01|    01|2008-01-01|\n",
      "|  1|2007| 01|    01|2007-01-01|\n",
      "|  3|2016| 01|    03|2016-03-01|\n",
      "|  3|2007| 01|    03|2007-03-01|\n",
      "|  3|2004| 01|    03|2004-03-01|\n",
      "|  3|2012| 01|    03|2012-03-01|\n",
      "|  3|2008| 01|    03|2008-03-01|\n",
      "|  3|2006| 01|    03|2006-03-01|\n",
      "+---+----+---+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Se crea nueva columna fecha para el data frame de vuelos.\n",
    "vuelos_fecha_df_whitout_duplicates = vuelos_fecha_df_whitout_duplicates.withColumn('fecha', date_format(to_date(concat(col(\"dia\"),col(\"NewMes\"),col(\"ano\")), \"ddMMyyyy\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "print(vuelos_fecha_df_whitout_duplicates.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El data_frame_vuelos_final : \n",
      "+----------+\n",
      "|     fecha|\n",
      "+----------+\n",
      "|2017-01-01|\n",
      "|2010-01-01|\n",
      "|2011-01-01|\n",
      "|2015-01-01|\n",
      "|2013-01-01|\n",
      "|2004-01-01|\n",
      "|2006-01-01|\n",
      "|2012-01-01|\n",
      "|2016-01-01|\n",
      "|2005-01-01|\n",
      "|2014-01-01|\n",
      "|2009-01-01|\n",
      "|2008-01-01|\n",
      "|2007-01-01|\n",
      "|2016-03-01|\n",
      "|2007-03-01|\n",
      "|2004-03-01|\n",
      "|2012-03-01|\n",
      "|2008-03-01|\n",
      "|2006-03-01|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#se crea data frame de vuelos final\n",
    "data_frame_vuelos_final = vuelos_fecha_df_whitout_duplicates.selectExpr('fecha AS fecha')\n",
    "print('El data_frame_vuelos_final : ')\n",
    "data_frame_vuelos_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T4. Se unen dafarames de aeropuertos y vuelos ,se eliminan duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|descripcion|\n",
      "+-----------+\n",
      "| 2015-06-05|\n",
      "| 2013-04-26|\n",
      "| 2009-05-07|\n",
      "| 2013-11-19|\n",
      "| 2013-03-20|\n",
      "| 2014-11-11|\n",
      "| 2012-10-25|\n",
      "| 2009-10-06|\n",
      "| 2012-08-16|\n",
      "| 2013-05-16|\n",
      "| 2014-02-28|\n",
      "| 2013-05-03|\n",
      "| 2013-12-05|\n",
      "| 2013-07-24|\n",
      "| 2010-08-19|\n",
      "| 2015-01-27|\n",
      "| 2013-09-24|\n",
      "| 2014-12-15|\n",
      "| 2014-01-21|\n",
      "| 2014-01-31|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total registros aeropuertos_fc_df::213\n",
      "Total registros aeropuertos_fv_df::85\n",
      "Total registros union1::298\n"
     ]
    }
   ],
   "source": [
    "df_union_fechas1 = aeropuertos_fc_df.withColumnRenamed('fecha', 'descripcion') \\\n",
    "        .union(aeropuertos_fv_df.withColumnRenamed('fecha', 'descripcion'))\n",
    "df_union_fechas1.show()\n",
    "print(\"Total registros aeropuertos_fc_df::\"+str(aeropuertos_fc_df.count()))\n",
    "print(\"Total registros aeropuertos_fv_df::\"+str(aeropuertos_fv_df.count()))\n",
    "\n",
    "print(\"Total registros union1::\"+str(df_union_fechas1.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|descripcion|\n",
      "+-----------+\n",
      "| 2015-06-05|\n",
      "| 2013-04-26|\n",
      "| 2009-05-07|\n",
      "| 2013-11-19|\n",
      "| 2013-03-20|\n",
      "| 2014-11-11|\n",
      "| 2012-10-25|\n",
      "| 2009-10-06|\n",
      "| 2012-08-16|\n",
      "| 2013-05-16|\n",
      "| 2014-02-28|\n",
      "| 2013-05-03|\n",
      "| 2013-12-05|\n",
      "| 2013-07-24|\n",
      "| 2010-08-19|\n",
      "| 2015-01-27|\n",
      "| 2013-09-24|\n",
      "| 2014-12-15|\n",
      "| 2014-01-21|\n",
      "| 2014-01-31|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total registros df_union_fechas1::298\n",
      "Total registros aeropuertos_fv_df::168\n",
      "Total registros union2::466\n"
     ]
    }
   ],
   "source": [
    "df_union_fechas2 = df_union_fechas1.withColumnRenamed('fecha', 'descripcion') \\\n",
    "        .union(data_frame_vuelos_final.withColumnRenamed('fecha', 'descripcion'))\n",
    "df_union_fechas2.show()\n",
    "print(\"Total registros df_union_fechas1::\"+str(df_union_fechas1.count()))\n",
    "print(\"Total registros aeropuertos_fv_df::\"+str(data_frame_vuelos_final.count()))\n",
    "\n",
    "print(\"Total registros union2::\"+str(df_union_fechas2.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total registros final::406\n"
     ]
    }
   ],
   "source": [
    "# Eliminar registros duplicados\n",
    "df_union_fechas2 = df_union_fechas2.distinct()\n",
    "print(\"Total registros final::\"+str(df_union_fechas2.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T5. crear columna descripcion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMACION\n",
    "fecha_final = df_union_fechas2.selectExpr('descripcion AS descripcion')\n",
    "fecha_final = fecha_final.coalesce(1).withColumn(\"idFecha\", date_format(col(\"descripcion\"), \"yyyyMMdd\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T6. crear columna mes, anio, dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+----+\n",
      "| idFecha|descripcion|Dia|Mes|Anio|\n",
      "+--------+-----------+---+---+----+\n",
      "|20150227| 2015-02-27| 27| 02|2015|\n",
      "|20070101| 2007-01-01| 01| 01|2007|\n",
      "|20050201| 2005-02-01| 01| 02|2005|\n",
      "|20091001| 2009-10-01| 01| 10|2009|\n",
      "|20120817| 2012-08-17| 17| 08|2012|\n",
      "+--------+-----------+---+---+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total registros final::406\n"
     ]
    }
   ],
   "source": [
    "fecha_final = fecha_final.coalesce(1).withColumn(\"Dia\", date_format(col(\"descripcion\"), \"dd\"))\n",
    "fecha_final = fecha_final.coalesce(1).withColumn(\"Mes\", date_format(col(\"descripcion\"), \"MM\"))\n",
    "fecha_final = fecha_final.coalesce(1).withColumn(\"Anio\", date_format(col(\"descripcion\"), \"yyyy\"))\n",
    "fecha_final = fecha_final.select('idFecha','descripcion','Dia','Mes','Anio')\n",
    "fecha_final.show(5)\n",
    "print(\"Total registros final::\"+str(fecha_final.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga\n",
    "Se carga el dataframe procesado en una nueva tabla segun el diseño de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, fecha_final,'Proyecto_G5_202413.G5_Fecha', db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #7: Mini Dimensión Aeropuerto\n",
    "\n",
    "En este paso aplicaremos ETL a la Dimension **MiniDimensionAeropuerto**, su fuente de datos viene de la tabla `aeropuertos` de la base de datos de ProyectoTransaccional.\n",
    "\n",
    "Al final del proceso de ETL se espera obtener una nueva tabla llamada `G5_MiniDimensionAeropuerto` en la base de datos de Proyecto_G5_202413 conteniendo las siguiente columnas:\n",
    "* idMini_DWH\n",
    "* rangoLongitudPista\n",
    "* rangoAnchoPista\n",
    "* rangoNumeroVuelosOrigen\n",
    "* clase\n",
    "* tipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraccion\n",
    "\n",
    "En esta seccion obtendremos los datos de las fuentes identificadas en nuestro diseño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de registros obtenidos de la union de las tablas G5_Aeropuertos y Aeropuertos fueron: 1194\n",
      "La tabla extraida queda de la siguiente forma:\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+\n",
      "|idAeropuerto_DWH|sigla|longitud_pista|ancho_pista|numero_vuelos_origen|clase|      tipo|Anio|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+\n",
      "|               1|  7FO|          1170|         14|              171525|   1A|   Privado|2015|\n",
      "|               1|  7FO|          1273|         15|              571675|   1A|   Privado|2016|\n",
      "|               1|  7FO|          1597|         18|              994420|   1A|   Privado|2017|\n",
      "|               2|  7FU|           667|         16|              252325|   1A|Fumigación|2015|\n",
      "|               2|  7FU|           337|         13|              126667|   1A|Fumigación|2016|\n",
      "|               2|  7FU|           178|         13|              175953|   1A|Fumigación|2017|\n",
      "|               3|  7FW|           514|          8|              444936|   1A|   Privado|2015|\n",
      "|               3|  7FW|           302|          4|             -253202|   1A|   Privado|2016|\n",
      "|               3|  7FW|           180|          4|              289424|   1A|   Privado|2017|\n",
      "|               4|  7FX|           283|          8|               38246|   1A|   Público|2015|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sql_aeropuerto = '''(SELECT DISTINCT ae.sigla, ae.longitud_pista, ae.ancho_pista, ae.numero_vuelos_origen, ae.clase, ae.tipo, ae.anio FROM ProyectoTransaccional.aeropuertos ae ORDER BY ae.sigla, ae.Anio ASC LIMIT 1000) AS Temp_Aeropuertos'''\n",
    "sql_aeropuerto = '''(SELECT DISTINCT ga.idAeropuerto_DWH, ae.sigla, ae.longitud_pista, ae.ancho_pista, ae.numero_vuelos_origen, ae.clase, ae.tipo, ae.Anio \n",
    "FROM ProyectoTransaccional.aeropuertos ae JOIN Proyecto_G5_202413.G5_Aeropuerto ga ON ae.sigla = ga.Sigla) as Temp_G5Aeropuertos'''\n",
    "aeropuertos_df = obtener_dataframe_de_bd(source_db_connection_string, sql_aeropuerto, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de registros obtenidos de la union de las tablas G5_Aeropuertos y Aeropuertos fueron: ' + str(aeropuertos_df.count()))\n",
    "print('La tabla extraida queda de la siguiente forma:')\n",
    "aeropuertos_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T1. Eliminar duplicados totales de la tabla:\n",
    "\n",
    "Esta transformacion fue aplicada en la sentencia SQL de la etapa de Extraccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de duplicados totales es de 0\n"
     ]
    }
   ],
   "source": [
    "aeropuertos_dt = aeropuertos_df.count() - aeropuertos_df.distinct().count()\n",
    "print('La cantidad de duplicados totales es de ' + str(aeropuertos_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T2. Tomar la información de la columna numero_vuelos_origen multiplicando por -1 cuando vengan valores negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+\n",
      "|idAeropuerto_DWH|sigla|longitud_pista|ancho_pista|numero_vuelos_origen|clase|      tipo|Anio|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+\n",
      "|               1|  7FO|          1170|         14|              171525|   1A|   Privado|2015|\n",
      "|               1|  7FO|          1273|         15|              571675|   1A|   Privado|2016|\n",
      "|               1|  7FO|          1597|         18|              994420|   1A|   Privado|2017|\n",
      "|               2|  7FU|           667|         16|              252325|   1A|Fumigación|2015|\n",
      "|               2|  7FU|           337|         13|              126667|   1A|Fumigación|2016|\n",
      "|               2|  7FU|           178|         13|              175953|   1A|Fumigación|2017|\n",
      "|               3|  7FW|           514|          8|              444936|   1A|   Privado|2015|\n",
      "|               3|  7FW|           302|          4|              253202|   1A|   Privado|2016|\n",
      "|               3|  7FW|           180|          4|              289424|   1A|   Privado|2017|\n",
      "|               4|  7FX|           283|          8|               38246|   1A|   Público|2015|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos_df = aeropuertos_df.withColumn(\"numero_vuelos_origen\", when(col(\"numero_vuelos_origen\") < 0, col(\"numero_vuelos_origen\") * -1).otherwise(col(\"numero_vuelos_origen\")))\n",
    "aeropuertos_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar el rango cuartil con base a la información ingresada\n",
    "\n",
    "def generar_rango_cuartil(df, partition_by, order_by, p_rank, column_name):\n",
    "    windowSpec = Window.partitionBy(partition_by).orderBy(order_by)\n",
    "    aeropuertos = df.withColumn(p_rank, percent_rank().over(windowSpec))\n",
    "    aeropuertos = aeropuertos.withColumn(\n",
    "        column_name,\n",
    "        when(col(p_rank) < 0.25, \"R1\")\n",
    "        .when((col(p_rank) >= 0.25) & (col(p_rank) < 0.50), \"R2\")\n",
    "        .when((col(p_rank) >= 0.50) & (col(p_rank) < 0.75), \"R3\")\n",
    "        .otherwise(\"R4\")\n",
    "    )\n",
    "    return aeropuertos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3. Crear la columna rangoNumeroVuelosOrigen categorizando la información en R1:[0-valor del 25%), R2:[Valor del 25%,Valor del 50%), R3: [Valor del 50%, Valor del 75%), R4: > valor del 75%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+\n",
      "|idAeropuerto_DWH|sigla|longitud_pista|ancho_pista|numero_vuelos_origen|clase|      tipo|Anio|pr_vuelos_p|rangoNumeroVuelosOrigen|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+\n",
      "|               1|  7FO|          1170|         14|              171525|   1A|   Privado|2015|        0.0|                     R1|\n",
      "|               1|  7FO|          1273|         15|              571675|   1A|   Privado|2016|        0.5|                     R3|\n",
      "|               1|  7FO|          1597|         18|              994420|   1A|   Privado|2017|        1.0|                     R4|\n",
      "|               2|  7FU|           337|         13|              126667|   1A|Fumigación|2016|        0.0|                     R1|\n",
      "|               2|  7FU|           178|         13|              175953|   1A|Fumigación|2017|        0.5|                     R3|\n",
      "|               2|  7FU|           667|         16|              252325|   1A|Fumigación|2015|        1.0|                     R4|\n",
      "|               3|  7FW|           302|          4|              253202|   1A|   Privado|2016|        0.0|                     R1|\n",
      "|               3|  7FW|           180|          4|              289424|   1A|   Privado|2017|        0.5|                     R3|\n",
      "|               3|  7FW|           514|          8|              444936|   1A|   Privado|2015|        1.0|                     R4|\n",
      "|               4|  7FX|           232|          4|               18764|   1A|   Público|2017|        0.0|                     R1|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos_df = generar_rango_cuartil(aeropuertos_df, 'sigla', 'numero_vuelos_origen', 'pr_vuelos_p', 'rangoNumeroVuelosOrigen')\n",
    "aeropuertos_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T4. Crear la columna rangoLongitudPista categorizando la información en R1:[0-valor del 25%), R2:[Valor del 25%,Valor del 50%), R3: [Valor del 50%, Valor del 75%), R4: > valor del 75%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+-------------+------------------+\n",
      "|idAeropuerto_DWH|sigla|longitud_pista|ancho_pista|numero_vuelos_origen|clase|      tipo|Anio|pr_vuelos_p|rangoNumeroVuelosOrigen|pr_longitud_p|rangoLongitudPista|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+-------------+------------------+\n",
      "|               1|  7FO|          1170|         14|              171525|   1A|   Privado|2015|        0.0|                     R1|          0.0|                R1|\n",
      "|               1|  7FO|          1273|         15|              571675|   1A|   Privado|2016|        0.5|                     R3|          0.5|                R3|\n",
      "|               1|  7FO|          1597|         18|              994420|   1A|   Privado|2017|        1.0|                     R4|          1.0|                R4|\n",
      "|               2|  7FU|           178|         13|              175953|   1A|Fumigación|2017|        0.5|                     R3|          0.0|                R1|\n",
      "|               2|  7FU|           337|         13|              126667|   1A|Fumigación|2016|        0.0|                     R1|          0.5|                R3|\n",
      "|               2|  7FU|           667|         16|              252325|   1A|Fumigación|2015|        1.0|                     R4|          1.0|                R4|\n",
      "|               3|  7FW|           180|          4|              289424|   1A|   Privado|2017|        0.5|                     R3|          0.0|                R1|\n",
      "|               3|  7FW|           302|          4|              253202|   1A|   Privado|2016|        0.0|                     R1|          0.5|                R3|\n",
      "|               3|  7FW|           514|          8|              444936|   1A|   Privado|2015|        1.0|                     R4|          1.0|                R4|\n",
      "|               4|  7FX|           232|          4|               18764|   1A|   Público|2017|        0.0|                     R1|          0.0|                R1|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+-------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos_df = generar_rango_cuartil(aeropuertos_df, 'sigla', 'longitud_pista', 'pr_longitud_p', 'rangoLongitudPista')\n",
    "aeropuertos_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5. Crear la columna rangoAnchoPista categorizando la información en R1:[0-valor del 25%), R2:[Valor del 25%,Valor del 50%), R3: [Valor del 50%, Valor del 75%), R4: > valor del 75%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+-------------+------------------+----------+---------------+\n",
      "|idAeropuerto_DWH|sigla|longitud_pista|ancho_pista|numero_vuelos_origen|clase|      tipo|Anio|pr_vuelos_p|rangoNumeroVuelosOrigen|pr_longitud_p|rangoLongitudPista|pr_ancho_p|rangoAnchoPista|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+-------------+------------------+----------+---------------+\n",
      "|               1|  7FO|          1170|         14|              171525|   1A|   Privado|2015|        0.0|                     R1|          0.0|                R1|       0.0|             R1|\n",
      "|               1|  7FO|          1273|         15|              571675|   1A|   Privado|2016|        0.5|                     R3|          0.5|                R3|       0.5|             R3|\n",
      "|               1|  7FO|          1597|         18|              994420|   1A|   Privado|2017|        1.0|                     R4|          1.0|                R4|       1.0|             R4|\n",
      "|               2|  7FU|           178|         13|              175953|   1A|Fumigación|2017|        0.5|                     R3|          0.0|                R1|       0.0|             R1|\n",
      "|               2|  7FU|           337|         13|              126667|   1A|Fumigación|2016|        0.0|                     R1|          0.5|                R3|       0.0|             R1|\n",
      "|               2|  7FU|           667|         16|              252325|   1A|Fumigación|2015|        1.0|                     R4|          1.0|                R4|       1.0|             R4|\n",
      "|               3|  7FW|           180|          4|              289424|   1A|   Privado|2017|        0.5|                     R3|          0.0|                R1|       0.0|             R1|\n",
      "|               3|  7FW|           302|          4|              253202|   1A|   Privado|2016|        0.0|                     R1|          0.5|                R3|       0.0|             R1|\n",
      "|               3|  7FW|           514|          8|              444936|   1A|   Privado|2015|        1.0|                     R4|          1.0|                R4|       1.0|             R4|\n",
      "|               4|  7FX|           232|          4|               18764|   1A|   Público|2017|        0.0|                     R1|          0.0|                R1|       0.0|             R1|\n",
      "+----------------+-----+--------------+-----------+--------------------+-----+----------+----+-----------+-----------------------+-------------+------------------+----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeropuertos_df = generar_rango_cuartil(aeropuertos_df, 'sigla', 'ancho_pista', 'pr_ancho_p', 'rangoAnchoPista')\n",
    "aeropuertos_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T6. Rellenar valores vacíos de la columna Tipo con valores por defecto 'Sin tipo':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos_df = aeropuertos_df.withColumn('clase',f.when(f.col('clase').isNull() | (f.col('clase') == ''), 'Sin clase').otherwise(f.col('clase')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T7. Rellenar valores vacíos de la columna Clase con valores por defecto 'Sin clase':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeropuertos_df = aeropuertos_df.withColumn('tipo',f.when(f.col('tipo').isNull() | (f.col('tipo') == ''), 'Sin tipo').otherwise(f.col('tipo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T8. Creación de la columna idMini_DWH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla Transformada queda de la siguiente forma: \n",
      "Numero de regiustros en minidimension: 194\n",
      "+----------+------------------+---------------+-----------------------+-----+----------+\n",
      "|idMini_DWH|rangoLongitudPista|rangoAnchoPista|rangoNumeroVuelosOrigen|clase|      tipo|\n",
      "+----------+------------------+---------------+-----------------------+-----+----------+\n",
      "|         1|                R3|             R3|                     R4|   3C| Aerocivil|\n",
      "|         2|                R1|             R1|                     R1|   0B| Aerocivil|\n",
      "|         3|                R3|             R3|                     R4|   1A|Fumigación|\n",
      "|         4|                R1|             R1|                     R1|   2C|   Público|\n",
      "|         5|                R1|             R1|                     R4|   2A|   Privado|\n",
      "|         6|                R4|             R4|                     R3|   4C| Aerocivil|\n",
      "|         7|                R4|             R4|                     R3|   1A|Fumigación|\n",
      "|         8|                R1|             R1|                     R1|   4E| Aerocivil|\n",
      "|         9|                R1|             R1|                     R1|   4B|   Militar|\n",
      "|        10|                R4|             R4|                     R4|   UL|   Privado|\n",
      "|        11|                R3|             R1|                     R4|   1A|   Público|\n",
      "|        12|                R3|             R3|                     R3|   2C| Aerocivil|\n",
      "|        13|                R3|             R3|                     R1|   1A|Fumigación|\n",
      "|        14|                R3|             R1|                     R3|   1A|   Público|\n",
      "|        15|                R4|             R3|                     R4|   3C| Aerocivil|\n",
      "|        16|                R3|             R3|                     R4|   2A|   Privado|\n",
      "|        17|                R4|             R4|                     R3|   2A| Aerocivil|\n",
      "|        18|                R1|             R1|                     R1|   2B|   Privado|\n",
      "|        19|                R3|             R3|                     R4|   4E| Aerocivil|\n",
      "|        20|                R1|             R1|                     R1|   2C|   Privado|\n",
      "+----------+------------------+---------------+-----------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mini_dimension_aeropuerto_df = aeropuertos_df.select('rangoLongitudPista', 'rangoAnchoPista', 'rangoNumeroVuelosOrigen', 'clase', 'tipo')\n",
    "mini_dimension_aeropuerto_df = mini_dimension_aeropuerto_df.distinct()\n",
    "mini_dimension_aeropuerto_df = mini_dimension_aeropuerto_df.coalesce(1).withColumn('idMini_DWH', f.monotonically_increasing_id() + 1)\n",
    "mini_dimension_aeropuerto_df = mini_dimension_aeropuerto_df.select('idMini_DWH','rangoLongitudPista', 'rangoAnchoPista', 'rangoNumeroVuelosOrigen', 'clase', 'tipo')\n",
    "print('La tabla Transformada queda de la siguiente forma: ')\n",
    "print('Numero de regiustros en minidimension: ' + str(mini_dimension_aeropuerto_df.count()))\n",
    "mini_dimension_aeropuerto_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga\n",
    "Se carga el dataframe procesado en una nueva tabla segun el diseño de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, mini_dimension_aeropuerto_df,'Proyecto_G5_202413.G5_MiniDimensionAeropuerto', db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #8: Hecho Historia Cambio\n",
    "\n",
    "En este paso aplicaremos ETL a la Dimension **HechoHistoriaCambios**, su fuente de datos viene de las tablas `G5_Aeropuerto`, `G5_Aeropuerto`, `G5_miniDimensionAeropuerto` y  `G5_Fecha` de la base de datos de Proyecto_G5_202413.\n",
    "\n",
    "Al final del proceso de ETL se espera obtener una nueva tabla llamada `G5_HechoHistoriaCambios` en la base de datos de Proyecto_G5_202413 conteniendo las siguiente columnas:\n",
    "* cambio\n",
    "* fechaInicio\n",
    "* fechaFin\n",
    "* idMini_DWH\n",
    "* idAeropuerto_DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraccion\n",
    "\n",
    "En esta seccion obtendremos los datos de las fuentes identificadas en nuestro diseño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de Registros de la tabla Aeropuertos obtenidos fueron: 1194\n",
      "La tabla extraida queda de la siguiente forma:\n",
      "+----------------+----------+----+\n",
      "|idAeropuerto_DWH|idMini_DWH|anio|\n",
      "+----------------+----------+----+\n",
      "|               1|        82|2015|\n",
      "|               1|       122|2016|\n",
      "|               1|        63|2017|\n",
      "|               2|        23|2017|\n",
      "|               2|       153|2016|\n",
      "|               2|        81|2015|\n",
      "|               3|       133|2017|\n",
      "|               3|       115|2016|\n",
      "|               3|        63|2015|\n",
      "|               4|       144|2017|\n",
      "+----------------+----------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hecho_hist_cambios_df = mini_dimension_aeropuerto_df.join(aeropuertos_df, on=[\"rangoLongitudPista\", \"rangoAnchoPista\", \"rangoNumeroVuelosOrigen\", \"clase\", \"tipo\"],\n",
    "    how=\"inner\")\n",
    "print('La cantidad de Registros de la tabla Aeropuertos obtenidos fueron: ' + str(hecho_hist_cambios_df.count()))\n",
    "print('La tabla extraida queda de la siguiente forma:')\n",
    "hecho_hist_cambios_df = hecho_hist_cambios_df.select('idAeropuerto_DWH','idMini_DWH', 'anio')\n",
    "hecho_hist_cambios_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T1. Creamos la columna `fechaInicio` a partir de la columna `anio` concatenando `0101`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----+-----------+\n",
      "|idAeropuerto_DWH|idMini_DWH|anio|fechaInicio|\n",
      "+----------------+----------+----+-----------+\n",
      "|             288|         1|2016|   20160101|\n",
      "|             274|         1|2016|   20160101|\n",
      "|             225|         2|2015|   20150101|\n",
      "|             220|         3|2016|   20160101|\n",
      "|             173|         3|2016|   20160101|\n",
      "|             172|         3|2016|   20160101|\n",
      "|             169|         3|2016|   20160101|\n",
      "|             158|         3|2016|   20160101|\n",
      "|             157|         3|2016|   20160101|\n",
      "|             156|         3|2016|   20160101|\n",
      "+----------------+----------+----+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hecho_hist_cambios_df = hecho_hist_cambios_df.withColumn(\"fechaInicio\", f.concat(f.col('anio'), f.lit('0101')))\n",
    "hecho_hist_cambios_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T2. Creamos la columna `fechaFin` a partir de la columna `anio` concatenando `0101`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----+-----------+--------+\n",
      "|idAeropuerto_DWH|idMini_DWH|anio|fechaInicio|fechaFin|\n",
      "+----------------+----------+----+-----------+--------+\n",
      "|             288|         1|2016|   20160101|20160101|\n",
      "|             274|         1|2016|   20160101|20160101|\n",
      "|             225|         2|2015|   20150101|20150101|\n",
      "|             220|         3|2016|   20160101|20160101|\n",
      "|             173|         3|2016|   20160101|20160101|\n",
      "|             172|         3|2016|   20160101|20160101|\n",
      "|             169|         3|2016|   20160101|20160101|\n",
      "|             158|         3|2016|   20160101|20160101|\n",
      "|             157|         3|2016|   20160101|20160101|\n",
      "|             156|         3|2016|   20160101|20160101|\n",
      "+----------------+----------+----+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hecho_hist_cambios_df = hecho_hist_cambios_df.withColumn(\"fechaFin\", f.concat(f.col('anio'), f.lit('0101')))\n",
    "hecho_hist_cambios_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3. Creamos la columna `cambio` con el valor constante `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------+-----------+--------+\n",
      "|cambio|idAeropuerto_DWH|idMini_DWH|fechaInicio|fechaFin|\n",
      "+------+----------------+----------+-----------+--------+\n",
      "|     1|             288|         1|   20160101|20160101|\n",
      "|     1|             274|         1|   20160101|20160101|\n",
      "|     1|             225|         2|   20150101|20150101|\n",
      "|     1|             220|         3|   20160101|20160101|\n",
      "|     1|             173|         3|   20160101|20160101|\n",
      "|     1|             172|         3|   20160101|20160101|\n",
      "|     1|             169|         3|   20160101|20160101|\n",
      "|     1|             158|         3|   20160101|20160101|\n",
      "|     1|             157|         3|   20160101|20160101|\n",
      "|     1|             156|         3|   20160101|20160101|\n",
      "+------+----------------+----------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hecho_hist_cambios_df = hecho_hist_cambios_df.withColumn(\"cambio\", f.lit('1'))\n",
    "hecho_hist_cambios_df = hecho_hist_cambios_df.select('cambio', 'idAeropuerto_DWH', 'idMini_DWH','fechaInicio','fechaFin')\n",
    "hecho_hist_cambios_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga\n",
    "Se carga el dataframe procesado en una nueva tabla segun el diseño de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, hecho_hist_cambios_df,'Proyecto_G5_202413.G5_HechoHistoriaCambios', db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #9: Hecho Vuelo\n",
    "\n",
    "En este paso aplicaremos ETL para la creacion del **HehcoVuelo**, su fuente de datos viene de las tablas `vuelos` de la base de datos de WWImportersProyectoTransaccionalTransactional y de las Tablas `G5_Aeropuerto`, `G5_miniDimensionAeropuerto`, `G5_Fecha`, `G5_GeografiaconDemografia`, `G5_Trafico` y `G5_TipoVuelo` de la base de datos de Proyecto_G5_202413.\n",
    "\n",
    "Al final del proceso de ETL se espera obtener una nueva tabla llamada `G5_HechoVuelo` en la base de datos de Estudiante_103_202413 conteniendo las siguiente columnas:\n",
    "* idFecha\n",
    "* idAeropuertoOrigen_DWH\n",
    "* idAeropuertoDestino_DWH\n",
    "* idMiniMomentoDelHechoOrigen_DWH\n",
    "* idMunicipioOrigen_DWH\n",
    "* idMunicipioDestino_DWH\n",
    "* idTrafico_DWH\n",
    "* idTipoVuelo_DWH\n",
    "* Vuelos\n",
    "* Sillas\n",
    "* CargaOfrecida\n",
    "* Pasajeros\n",
    "* CargaAbordo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraccion\n",
    "\n",
    "En esta seccion obtendremos los datos de las fuentes identificadas en nuestro diseño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de Registros de Transaccion de Movimientos obtenidas fueron: 562430\n",
      "La tabla extraida queda de la siguiente forma:\n",
      "+----+---+------+-------+----------+-------+-----------+------+------+-------------+---------+-----------+\n",
      "| ano|mes|origen|destino|tipo_vuelo|trafico|tipo_equipo|Vuelos|Sillas|CargaOfrecida|Pasajeros|CargaAbordo|\n",
      "+----+---+------+-------+----------+-------+-----------+------+------+-------------+---------+-----------+\n",
      "|2012|  9|   uib|    axm|         R|      N|       JS32|     2|    35|        412.0|        2|        0.0|\n",
      "|2012| 11|   uib|    axm|         R|      N|       JS32|     2|    35|        416.0|        2|        0.0|\n",
      "|2012| 12|   uib|    axm|         R|      N|       JS32|     4|    69|        830.0|        6|        0.0|\n",
      "|2012| 11|   uib|    bga|         R|      N|       JS32|     1|    17|        206.0|        1|        0.0|\n",
      "|2012|  1|   uib|    bsc|         R|      N|       DHC6|    14|   223|       2786.0|      126|      143.0|\n",
      "|2012|  2|   uib|    bsc|         R|      N|       DHC6|     2|    32|        398.0|       19|        0.0|\n",
      "|2004|  1|   bog|    mia|         R|      I|       A306|    32|  8000|     362880.0|     6423|   226429.0|\n",
      "|2012|  3|   uib|    bsc|         R|      N|       DHC6|     2|    32|        402.0|       20|       43.0|\n",
      "|2004|  2|   bog|    mia|         R|      I|       A306|    29|  7743|     328860.0|     4107|   237123.0|\n",
      "|2012|  4|   uib|    bsc|         R|      N|       DHC6|     3|    46|        583.0|       26|      124.0|\n",
      "|2004|  3|   bog|    mia|         R|      I|       A306|    31|  8277|     351540.0|     4332|   269443.0|\n",
      "|2012|  5|   uib|    bsc|         R|      N|       DHC6|     2|    30|        374.0|       15|       18.0|\n",
      "|2004|  4|   bog|    mia|         R|      I|       A306|    30|  8010|     340200.0|     4207|   255167.0|\n",
      "|2012|  6|   uib|    bsc|         R|      N|       DHC6|     2|    30|        367.0|       13|       44.0|\n",
      "|2004|  5|   bog|    mia|         R|      I|       A306|     1|   267|      11340.0|      156|    10175.0|\n",
      "|2012|  7|   uib|    bsc|         R|      N|       DHC6|     1|    15|        187.0|        3|        0.0|\n",
      "|2004|  6|   bog|    mia|         R|      I|       A306|     0|     0|          0.0|        0|        0.0|\n",
      "|2012|  8|   uib|    bsc|         R|      N|       DHC6|     4|    60|        742.0|       38|      110.0|\n",
      "|2004|  7|   bog|    mia|         R|      I|       A306|     0|     0|          0.0|        0|        0.0|\n",
      "|2012| 10|   uib|    bsc|         R|      N|       DHC6|     5|    75|        930.0|       43|       58.0|\n",
      "+----+---+------+-------+----------+-------+-----------+------+------+-------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------\n",
      "La cantidad de Registros de la tabla Aeropuertos obtenidos fueron: 598\n",
      "La tabla extraida queda de la siguiente forma:\n",
      "+-----+-------------+\n",
      "|sigla|gcd_municipio|\n",
      "+-----+-------------+\n",
      "|  7FO|        50568|\n",
      "|  7FU|        50568|\n",
      "|  7FW|        85125|\n",
      "|  7FX|         5150|\n",
      "|  7FY|        23068|\n",
      "|  7FZ|        85230|\n",
      "|  7GA|        13001|\n",
      "|  7GB|        20250|\n",
      "|  7GC|        85430|\n",
      "|  7GD|        15572|\n",
      "|  7GE|        85230|\n",
      "|  7GF|        85250|\n",
      "|  7GG|        85139|\n",
      "|  7GH|        99001|\n",
      "|  7GI|        85230|\n",
      "|  7GK|        50150|\n",
      "|  7GL|        20400|\n",
      "|  7GN|        23068|\n",
      "|  7GO|        85325|\n",
      "|  7GP|        47545|\n",
      "+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_vuelos = '''(SELECT DISTINCT ano, mes, origen, destino,tipo_vuelo,trafico,tipo_equipo, vuelos AS Vuelos, sillas AS Sillas, carga_ofrecida AS CargaOfrecida, pasajeros AS Pasajeros, carga_bordo AS CargaAbordo FROM ProyectoTransaccional.vuelos) AS Temp_vuelos'''\n",
    "vuelos_temp = obtener_dataframe_de_bd(source_db_connection_string, sql_vuelos, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de Registros de Transaccion de Movimientos obtenidas fueron: ' + str(vuelos_temp.count()))\n",
    "print('La tabla extraida queda de la siguiente forma:')\n",
    "vuelos_temp.show()\n",
    "print('-------------------------')\n",
    "sql_aero = '''(SELECT DISTINCT sigla, gcd_municipio FROM ProyectoTransaccional.aeropuertos) AS Temp_aeropuerto'''\n",
    "aero_df = obtener_dataframe_de_bd(source_db_connection_string, sql_aero, db_shiomar, pass_shiomar)\n",
    "print('La cantidad de Registros de la tabla Aeropuertos obtenidos fueron: ' + str(aero_df.count()))\n",
    "print('La tabla extraida queda de la siguiente forma:')\n",
    "aero_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T1. Eliminar Duplicados Totales la tabla de Vuelos\n",
    "\n",
    "Esta transformacion fue aplicada en la sentencia SQL de la etapa de Extraccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de duplicados totales es de 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = vuelos_temp.count() - vuelos_temp.distinct().count()\n",
    "print('La cantidad de duplicados totales es de ' + str(duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T2. Preparación para Conexión de Tablas de dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla Transformada queda de la siguiente forma:\n"
     ]
    }
   ],
   "source": [
    "# Preparacion de tabla\n",
    "df_dic_fecha = pd.DataFrame({'mes': ['1','2','3','4','5','6','7','8','9','10','11','12'], 'NewMes': ['01', '02', '03','04','05','06','07','08','09','10','11','12']})\n",
    "diccionarioFecha=spark.createDataFrame(df_dic_fecha)\n",
    "vuelos_temp = vuelos_temp.join(diccionarioFecha,how = 'inner',  on='mes')\n",
    "vuelos_temp = vuelos_temp.drop('mes')\n",
    "vuelos_temp = vuelos_temp.withColumnRenamed('NewMes', 'mes')\n",
    "vuelos_temp = vuelos_temp.withColumn(\"Dia\", lit('01'))\n",
    "\n",
    "df = pd.DataFrame({'tipo_vuelo': ['R','T','C','A'], 'nombreTipo': ['regular', 'taxi', 'chárter', 'adicionales']})\n",
    "diccionarioTipoVuelo=spark.createDataFrame(df)\n",
    "vuelos_temp = vuelos_temp.join(diccionarioTipoVuelo,how = 'inner',  on='tipo_vuelo')\n",
    "vuelos_temp = vuelos_temp.drop('tipo_vuelo')\n",
    "\n",
    "vuelos_temp = vuelos_temp.withColumn('origen', upper(vuelos_temp['origen']))\n",
    "vuelos_temp = vuelos_temp.withColumn('destino', upper(vuelos_temp['destino']))\n",
    "\n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "vuelos_temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3. Conexión tablas dimensiones con Tabla Hechos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos_temp = vuelos_temp.alias('v').join(df_trafico.alias('tr'), (vuelos_temp.trafico == df_trafico.idTrafico_T),'left') \\\n",
    "                    .join(df_tipo_vuelos.alias('tv'), ((vuelos_temp.nombreTipo == df_tipo_vuelos.nombreTipo) & (vuelos_temp.tipo_equipo == df_tipo_vuelos.tipoEquipo)),'left') \\\n",
    "                    .join(aeropuerto_df.alias('a'), (vuelos_temp.origen == aeropuerto_df.Sigla),'left') \\\n",
    "                    .join(aero_df.alias('aero'), (vuelos_temp.origen == upper(aero_df.sigla)),'left')   \\\n",
    "                    .join(fecha_final.alias('fe'), ((vuelos_temp.mes == fecha_final.Mes) & (vuelos_temp.ano == fecha_final.Anio) & (vuelos_temp.Dia == fecha_final.Dia)) ,'left') \\\n",
    "                    .select([col('fe.idFecha'),col('a.idAeropuerto_DWH'),col('v.destino'), col('aero.gcd_municipio'),col('tv.idTipoVuelo_DWH'),col('tr.IdTrafico_DWH'),\n",
    "                             col('v.Vuelos'),col('v.Sillas'),col('v.CargaOfrecida'),col('v.Pasajeros'), col('v.CargaAbordo')]) \\\n",
    "                    .fillna({'gcd_municipio': 0, 'idAeropuerto_DWH': 0, })\n",
    "\n",
    "vuelos_temp = vuelos_temp.withColumnRenamed('idAeropuerto_DWH', 'idAeropuertoOrigen_DWH')\n",
    "vuelos_temp = vuelos_temp.withColumnRenamed('gcd_municipio', 'gcd_municipio_origen')\n",
    "                    \n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "vuelos_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = geografiaConDemografiaInitial.dropDuplicates(['ID_Municipio_T'])\n",
    "vuelos_temp = vuelos_temp.alias('v').join(aeropuerto_df.alias('a'), (vuelos_temp.destino == aeropuerto_df.Sigla),'left') \\\n",
    "                    .join(aero_df.alias('aero'), (vuelos_temp.destino == upper(aero_df.sigla)),'left')   \\\n",
    "                    .join(geo.alias('g'), (vuelos_temp.gcd_municipio_origen == geo.ID_Municipio_T),'left') \\\n",
    "                    .select([col('v.idFecha'),col('v.idAeropuertoOrigen_DWH'),col('a.idAeropuerto_DWH'), col('g.ID_Municipio_DWH'), col('aero.gcd_municipio'),col('v.idTipoVuelo_DWH'),col('v.IdTrafico_DWH'),\n",
    "                             col('v.Vuelos'),col('v.Sillas'),col('v.CargaOfrecida'),col('v.Pasajeros'), col('v.CargaAbordo')]) \\\n",
    "                    .fillna({'gcd_municipio': 0, 'idAeropuerto_DWH': 0,'ID_Municipio_DWH':0 })\n",
    "\n",
    "vuelos_temp = vuelos_temp.withColumnRenamed('idAeropuerto_DWH', 'idAeropuertoDestino_DWH')\n",
    "vuelos_temp = vuelos_temp.withColumnRenamed('gcd_municipio', 'gcd_municipio_destino')\n",
    "vuelos_temp = vuelos_temp.withColumnRenamed('ID_Municipio_DWH', 'idMunicipioOrigen_DWH')\n",
    "                    \n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "vuelos_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelos_temp = vuelos_temp.alias('v').join(geo.alias('g'), (vuelos_temp.gcd_municipio_destino == geo.ID_Municipio_T),'left') \\\n",
    "                    .select([col('v.idFecha'),col('v.idAeropuertoOrigen_DWH'),col('v.idAeropuertoDestino_DWH'), col('v.idMunicipioOrigen_DWH'), col('g.ID_Municipio_DWH'),col('v.idTipoVuelo_DWH'),col('v.IdTrafico_DWH'),\n",
    "                             col('v.Vuelos'),col('v.Sillas'),col('v.CargaOfrecida'),col('v.Pasajeros'), col('v.CargaAbordo')]) \\\n",
    "                    .fillna({'ID_Municipio_DWH': 0})\n",
    "vuelos_temp = vuelos_temp.withColumnRenamed('ID_Municipio_DWH', 'idMunicipioDestino_DWH')\n",
    "                    \n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "vuelos_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Window.partitionBy('idAeropuerto_DWH')\n",
    "\n",
    "mini_anio = aeropuertos_df.withColumn('maxAnio', spark_max('Anio').over(p))\\\n",
    "    .where(col('Anio') == col('maxAnio'))\\\n",
    "    .drop('maxAnio')\n",
    "#mini_anio.show()\n",
    "mini_anio.count() #598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " vuelos_2 = vuelos_temp.alias('v').join(mini_anio.alias('mini'), (vuelos_temp.idAeropuertoOrigen_DWH == mini_anio.idAeropuerto_DWH), 'left')\\\n",
    "                                .select([col('v.idFecha'),col('v.idAeropuertoOrigen_DWH'),col('v.idAeropuertoDestino_DWH'), col('v.idMunicipioOrigen_DWH'), col('v.idMunicipioDestino_DWH'),col('v.idTipoVuelo_DWH'),col('v.IdTrafico_DWH'),\n",
    "                             col('v.Vuelos'),col('v.Sillas'),col('v.CargaOfrecida'),col('v.Pasajeros'), col('v.CargaAbordo'), col('mini.rangoNumeroVuelosOrigen'), col('mini.rangoLongitudPista'), col('mini.rangoAnchoPista'), col('mini.tipo'), col('mini.clase')]) \n",
    "\n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "vuelos_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " vuelos_2 = vuelos_2.alias('v').join(mini_dimension_aeropuerto_df.alias('mini'),  ( (vuelos_2.rangoNumeroVuelosOrigen == mini_dimension_aeropuerto_df.rangoNumeroVuelosOrigen) & (vuelos_2.rangoLongitudPista == mini_dimension_aeropuerto_df.rangoLongitudPista) & (vuelos_2.rangoAnchoPista == mini_dimension_aeropuerto_df.rangoAnchoPista) & (vuelos_2.tipo == mini_dimension_aeropuerto_df.tipo) & (vuelos_2.clase == mini_dimension_aeropuerto_df.clase) ), 'left')\\\n",
    "                                .select([col('v.idFecha'),col('v.idAeropuertoOrigen_DWH'),col('v.idAeropuertoDestino_DWH'), col('v.idMunicipioOrigen_DWH'), col('v.idMunicipioDestino_DWH'),col('v.idTipoVuelo_DWH'),col('v.IdTrafico_DWH'),\n",
    "                             col('v.Vuelos'),col('v.Sillas'),col('v.CargaOfrecida'),col('v.Pasajeros'), col('v.CargaAbordo'), col('mini.idMini_DWH')]) \\\n",
    "                            .fillna({'idMini_DWH': 0})\n",
    "    \n",
    "vuelos_2 = vuelos_2.withColumnRenamed('idMini_DWH', 'idMiniMomentoDelHechoOrigen_DWH')\n",
    "\n",
    "print('La tabla Transformada queda de la siguiente forma:')\n",
    "vuelos_2.show()\n",
    "vuelos_2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga\n",
    "Se carga el dataframe procesado en una nueva tabla segun el diseño de ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, vuelos_2,'Proyecto_G5_202413.G5_HechoVuelo', db_shiomar, pass_shiomar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso #10: Clean Up\n",
    "En esta seccion haremos limpieza de la sesion de Spark, ya que hemos concluido con lo esperado en la actividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
